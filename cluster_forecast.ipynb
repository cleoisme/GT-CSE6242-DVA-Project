{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utils.ml_utils import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_prep import load_features_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the features data, these are popular trend following features used in prior literature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ret</th>\n",
       "      <th>rVol</th>\n",
       "      <th>1d_ret</th>\n",
       "      <th>1wk_ret</th>\n",
       "      <th>1m_ret</th>\n",
       "      <th>1Q_ret</th>\n",
       "      <th>6M_ret</th>\n",
       "      <th>12M_ret</th>\n",
       "      <th>feature_1d_ra</th>\n",
       "      <th>feature_1wk_ra</th>\n",
       "      <th>...</th>\n",
       "      <th>lag5_feature_MACD_short</th>\n",
       "      <th>lag5_feature_MACD_medium</th>\n",
       "      <th>lag5_feature_MACD_long</th>\n",
       "      <th>lag5_feature_skew6m</th>\n",
       "      <th>lag5_feature_skew12m</th>\n",
       "      <th>lag5_feature_kurt6m</th>\n",
       "      <th>lag5_feature_kurt12m</th>\n",
       "      <th>fwd_ret1d</th>\n",
       "      <th>target</th>\n",
       "      <th>targetBin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2024-03-15</th>\n",
       "      <th>15</th>\n",
       "      <td>0.052935</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>-0.009848</td>\n",
       "      <td>-0.017287</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.071679</td>\n",
       "      <td>0.201208</td>\n",
       "      <td>0.202884</td>\n",
       "      <td>-0.925114</td>\n",
       "      <td>-0.726237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118525</td>\n",
       "      <td>0.407592</td>\n",
       "      <td>0.856639</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>0.395266</td>\n",
       "      <td>2.899242</td>\n",
       "      <td>4.029588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.355712</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>0.082955</td>\n",
       "      <td>0.095509</td>\n",
       "      <td>0.074083</td>\n",
       "      <td>0.173772</td>\n",
       "      <td>0.341819</td>\n",
       "      <td>2.327878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464299</td>\n",
       "      <td>0.561470</td>\n",
       "      <td>0.464375</td>\n",
       "      <td>0.051510</td>\n",
       "      <td>0.388949</td>\n",
       "      <td>2.898267</td>\n",
       "      <td>4.018791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.049651</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>0.211590</td>\n",
       "      <td>0.529950</td>\n",
       "      <td>0.663190</td>\n",
       "      <td>0.577818</td>\n",
       "      <td>0.589546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115569</td>\n",
       "      <td>0.447172</td>\n",
       "      <td>0.922814</td>\n",
       "      <td>0.039734</td>\n",
       "      <td>0.385207</td>\n",
       "      <td>2.909077</td>\n",
       "      <td>4.015372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.818130</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.001021</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.038944</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.054041</td>\n",
       "      <td>0.345464</td>\n",
       "      <td>-0.100130</td>\n",
       "      <td>0.518333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049638</td>\n",
       "      <td>-0.360213</td>\n",
       "      <td>-0.198844</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.386226</td>\n",
       "      <td>2.867876</td>\n",
       "      <td>4.029249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.014050</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>-0.018105</td>\n",
       "      <td>-0.010729</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.143403</td>\n",
       "      <td>-0.036800</td>\n",
       "      <td>-0.004099</td>\n",
       "      <td>-1.713252</td>\n",
       "      <td>-0.454027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627858</td>\n",
       "      <td>0.650850</td>\n",
       "      <td>0.180584</td>\n",
       "      <td>-0.006129</td>\n",
       "      <td>0.376940</td>\n",
       "      <td>2.834308</td>\n",
       "      <td>3.977828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ret      rVol    1d_ret   1wk_ret    1m_ret  \\\n",
       "date       cluster                                                     \n",
       "2024-03-15 15       0.052935  0.010646 -0.009848 -0.017287  0.002016   \n",
       "           16       2.355712  0.010487  0.003585  0.054587  0.082955   \n",
       "           17       6.049651  0.010363  0.005988  0.013662  0.008980   \n",
       "           18       1.818130  0.010196 -0.001021  0.011817  0.038944   \n",
       "           19       1.014050  0.010568 -0.018105 -0.010729  0.088893   \n",
       "\n",
       "                      1Q_ret    6M_ret   12M_ret  feature_1d_ra  \\\n",
       "date       cluster                                                \n",
       "2024-03-15 15       0.071679  0.201208  0.202884      -0.925114   \n",
       "           16       0.095509  0.074083  0.173772       0.341819   \n",
       "           17       0.211590  0.529950  0.663190       0.577818   \n",
       "           18      -0.010944  0.054041  0.345464      -0.100130   \n",
       "           19       0.143403 -0.036800 -0.004099      -1.713252   \n",
       "\n",
       "                    feature_1wk_ra  ...  lag5_feature_MACD_short  \\\n",
       "date       cluster                  ...                            \n",
       "2024-03-15 15            -0.726237  ...                 0.118525   \n",
       "           16             2.327878  ...                 0.464299   \n",
       "           17             0.589546  ...                 0.115569   \n",
       "           18             0.518333  ...                -0.049638   \n",
       "           19            -0.454027  ...                 0.627858   \n",
       "\n",
       "                    lag5_feature_MACD_medium  lag5_feature_MACD_long  \\\n",
       "date       cluster                                                     \n",
       "2024-03-15 15                       0.407592                0.856639   \n",
       "           16                       0.561470                0.464375   \n",
       "           17                       0.447172                0.922814   \n",
       "           18                      -0.360213               -0.198844   \n",
       "           19                       0.650850                0.180584   \n",
       "\n",
       "                    lag5_feature_skew6m  lag5_feature_skew12m  \\\n",
       "date       cluster                                              \n",
       "2024-03-15 15                  0.066425              0.395266   \n",
       "           16                  0.051510              0.388949   \n",
       "           17                  0.039734              0.385207   \n",
       "           18                  0.021089              0.386226   \n",
       "           19                 -0.006129              0.376940   \n",
       "\n",
       "                    lag5_feature_kurt6m  lag5_feature_kurt12m  fwd_ret1d  \\\n",
       "date       cluster                                                         \n",
       "2024-03-15 15                  2.899242              4.029588        NaN   \n",
       "           16                  2.898267              4.018791        NaN   \n",
       "           17                  2.909077              4.015372        NaN   \n",
       "           18                  2.867876              4.029249        NaN   \n",
       "           19                  2.834308              3.977828        NaN   \n",
       "\n",
       "                    target  targetBin  \n",
       "date       cluster                     \n",
       "2024-03-15 15          NaN        NaN  \n",
       "           16          NaN        NaN  \n",
       "           17          NaN        NaN  \n",
       "           18          NaN        NaN  \n",
       "           19          NaN        NaN  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = load_features_data()\n",
    "feats.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the predictive features and target which is one day forward risk adjusted returns - drop na on this subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (117040, 79)\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in feats.columns if f.startswith(\"feature\")]\n",
    "lag_feats = [f for f in feats.columns if f.startswith(\"lag\")]\n",
    "target = [\"target\"]\n",
    "\n",
    "all_feats = features + target + lag_feats\n",
    "feats.dropna(subset=all_feats, inplace=True)\n",
    "feats = feats[all_feats]\n",
    "\n",
    "print(\"Shape of features\", feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break out X and y and set up cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feats[all_feats].copy()\n",
    "\n",
    "baseRF = RandomForestRegressor(max_depth=5, \n",
    "                               n_estimators=1000,\n",
    "                               max_features=int(1),\n",
    "                               n_jobs=-3)\n",
    "\n",
    "# simple-grid\n",
    "grid = {'n_estimators': np.arange(100, 1000, 100),\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'max_features': [int(1), 'sqrt'],\n",
    "        'min_weight_fraction_leaf': np.arange(0.0, 0.05, 0.005)}\n",
    "\n",
    "params = ParameterSampler(n_iter=25, param_distributions=grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Form the training loop, here we train on 3 year expanding windows, using 90% of each split for training and 10% for tuning hyper-parameters, we then use the same model to forecast forward 3-years before re-training again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(13626, 13) (1500, 13)\n",
      "Iter: 0: Score: 1.3397313566930171\n",
      "Iter: 1: Score: 1.345525274633928\n",
      "Iter: 2: Score: 1.3365385044086682\n",
      "Iter: 3: Score: 1.3369046968004257\n",
      "Iter: 4: Score: 1.3369205424596684\n",
      "Iter: 5: Score: 1.338609732396373\n",
      "Iter: 6: Score: 1.347388426348643\n",
      "Iter: 7: Score: 1.3369017352714256\n",
      "Iter: 8: Score: 1.3376600332812947\n",
      "Iter: 9: Score: 1.3361202229643547\n",
      "Iter: 10: Score: 1.3374012750602722\n",
      "Iter: 11: Score: 1.3496487757544722\n",
      "Iter: 12: Score: 1.3375422779642598\n",
      "Iter: 13: Score: 1.3387454043328562\n",
      "Iter: 14: Score: 1.3365181370161672\n",
      "Iter: 15: Score: 1.3369728200207018\n",
      "Iter: 16: Score: 1.3362784894960376\n",
      "Iter: 17: Score: 1.338226450065164\n",
      "Iter: 18: Score: 1.3362800042660212\n",
      "Iter: 19: Score: 1.33907438992572\n",
      "Iter: 20: Score: 1.3381081790002205\n",
      "Iter: 21: Score: 1.3380336643316648\n",
      "Iter: 22: Score: 1.338157449163515\n",
      "Iter: 23: Score: 1.3359969748498701\n",
      "Iter: 24: Score: 1.3366596936366995\n",
      "{'n_estimators': 800, 'min_weight_fraction_leaf': 0.01, 'max_features': 1, 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:25, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27252, 13) (3020, 13)\n",
      "Iter: 0: Score: 1.443540647589011\n",
      "Iter: 1: Score: 1.4429349189080458\n",
      "Iter: 2: Score: 1.445924156148313\n",
      "Iter: 3: Score: 1.4428475822893514\n",
      "Iter: 4: Score: 1.4431436464479817\n",
      "Iter: 5: Score: 1.443599920929328\n",
      "Iter: 6: Score: 1.4431155251252523\n",
      "Iter: 7: Score: 1.4431147866468095\n",
      "Iter: 8: Score: 1.443912480843022\n",
      "Iter: 9: Score: 1.4428546191092047\n",
      "Iter: 10: Score: 1.4484132886470036\n",
      "Iter: 11: Score: 1.4428105372211835\n",
      "Iter: 12: Score: 1.4437952190390737\n",
      "Iter: 13: Score: 1.4425370222422258\n",
      "Iter: 14: Score: 1.4425874496586506\n",
      "Iter: 15: Score: 1.4443828938571692\n",
      "Iter: 16: Score: 1.4427482623568788\n",
      "Iter: 17: Score: 1.4434206176452844\n",
      "Iter: 18: Score: 1.4439928202828232\n",
      "Iter: 19: Score: 1.4430660637690778\n",
      "Iter: 20: Score: 1.4625343033204263\n",
      "Iter: 21: Score: 1.4468367992527802\n",
      "Iter: 22: Score: 1.4432645499078882\n",
      "Iter: 23: Score: 1.4439796153445787\n",
      "Iter: 24: Score: 1.4449680801279583\n",
      "{'n_estimators': 600, 'min_weight_fraction_leaf': 0.045, 'max_features': 1, 'max_depth': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:02, 32.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40860, 13) (4540, 13)\n",
      "Iter: 0: Score: 1.3530363963627157\n",
      "Iter: 1: Score: 1.3536065370414125\n",
      "Iter: 2: Score: 1.353151170385124\n",
      "Iter: 3: Score: 1.3546694566588493\n",
      "Iter: 4: Score: 1.3536861431220026\n",
      "Iter: 5: Score: 1.3522372528415323\n",
      "Iter: 6: Score: 1.353984418588146\n",
      "Iter: 7: Score: 1.3537224827660914\n",
      "Iter: 8: Score: 1.3546709244906012\n",
      "Iter: 9: Score: 1.3536000663295504\n",
      "Iter: 10: Score: 1.353431265659952\n",
      "Iter: 11: Score: 1.3523421569588645\n",
      "Iter: 12: Score: 1.3538487508651396\n",
      "Iter: 13: Score: 1.3534915461521937\n",
      "Iter: 14: Score: 1.353497420081964\n",
      "Iter: 15: Score: 1.3538229113246942\n",
      "Iter: 16: Score: 1.3538382313662436\n",
      "Iter: 17: Score: 1.3538743689400177\n",
      "Iter: 18: Score: 1.3535383300403554\n",
      "Iter: 19: Score: 1.3536615883051288\n",
      "Iter: 20: Score: 1.3530149487653582\n",
      "Iter: 21: Score: 1.354187962435328\n",
      "Iter: 22: Score: 1.353804526928305\n",
      "Iter: 23: Score: 1.3545064275398757\n",
      "Iter: 24: Score: 1.3532688315831198\n",
      "{'n_estimators': 300, 'min_weight_fraction_leaf': 0.005, 'max_features': 1, 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:55, 41.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54468, 13) (6040, 13)\n",
      "Iter: 0: Score: 1.3278544938645371\n",
      "Iter: 1: Score: 1.3274615349169894\n",
      "Iter: 2: Score: 1.3276735210630264\n",
      "Iter: 3: Score: 1.328030542437902\n",
      "Iter: 4: Score: 1.3275579229850525\n",
      "Iter: 5: Score: 1.3279782255539576\n",
      "Iter: 6: Score: 1.327733686457855\n",
      "Iter: 7: Score: 1.327857776944277\n",
      "Iter: 8: Score: 1.3283022585356332\n",
      "Iter: 9: Score: 1.327714948840924\n",
      "Iter: 10: Score: 1.3289712503859676\n",
      "Iter: 11: Score: 1.3278807332452562\n",
      "Iter: 12: Score: 1.3298225342933385\n",
      "Iter: 13: Score: 1.3276261455084144\n",
      "Iter: 14: Score: 1.3284008634069613\n",
      "Iter: 15: Score: 1.3281702858366455\n",
      "Iter: 16: Score: 1.3288429391427625\n",
      "Iter: 17: Score: 1.327609172658639\n",
      "Iter: 18: Score: 1.3320252053603128\n",
      "Iter: 19: Score: 1.3276537143925513\n",
      "Iter: 20: Score: 1.327758058652162\n",
      "Iter: 21: Score: 1.3273451574385307\n",
      "Iter: 22: Score: 1.3302876838687328\n",
      "Iter: 23: Score: 1.3282726265816336\n",
      "Iter: 24: Score: 1.3286144649263092\n",
      "{'n_estimators': 100, 'min_weight_fraction_leaf': 0.04, 'max_features': 1, 'max_depth': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:19, 58.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68076, 13) (7560, 13)\n",
      "Iter: 0: Score: 1.301976780898697\n",
      "Iter: 1: Score: 1.3019398985026815\n",
      "Iter: 2: Score: 1.3017229487088977\n",
      "Iter: 3: Score: 1.3021210457777437\n",
      "Iter: 4: Score: 1.3020607800711408\n",
      "Iter: 5: Score: 1.3018661757577146\n",
      "Iter: 6: Score: 1.3020640459613042\n",
      "Iter: 7: Score: 1.3017148435046082\n",
      "Iter: 8: Score: 1.3019087403498055\n",
      "Iter: 9: Score: 1.30223230723133\n",
      "Iter: 10: Score: 1.3016559970064567\n",
      "Iter: 11: Score: 1.3018301097834077\n",
      "Iter: 12: Score: 1.3021042293122485\n",
      "Iter: 13: Score: 1.3017692084572203\n",
      "Iter: 14: Score: 1.3017173174997057\n",
      "Iter: 15: Score: 1.3017812713838528\n",
      "Iter: 16: Score: 1.3014511997230256\n",
      "Iter: 17: Score: 1.3018780816759716\n",
      "Iter: 18: Score: 1.3018941879694241\n",
      "Iter: 19: Score: 1.3016964055708873\n",
      "Iter: 20: Score: 1.3017062674829667\n",
      "Iter: 21: Score: 1.3019902470303937\n",
      "Iter: 22: Score: 1.303181000991906\n",
      "Iter: 23: Score: 1.3017463944762875\n",
      "Iter: 24: Score: 1.3018646305423307\n",
      "{'n_estimators': 200, 'min_weight_fraction_leaf': 0.01, 'max_features': 'sqrt', 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:19, 58.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81684, 13) (9060, 13)\n",
      "Iter: 0: Score: 1.3419159872864066\n",
      "Iter: 1: Score: 1.341994957534767\n",
      "Iter: 2: Score: 1.342276999449561\n",
      "Iter: 3: Score: 1.3421013103837451\n",
      "Iter: 4: Score: 1.3421179453026537\n",
      "Iter: 5: Score: 1.3421366642028054\n",
      "Iter: 6: Score: 1.3422656064540384\n",
      "Iter: 7: Score: 1.3431303112527373\n",
      "Iter: 8: Score: 1.3434249942584398\n",
      "Iter: 9: Score: 1.3425004226618333\n",
      "Iter: 10: Score: 1.342284581090663\n",
      "Iter: 11: Score: 1.3422364986604964\n",
      "Iter: 12: Score: 1.3427270853471847\n",
      "Iter: 13: Score: 1.342733320540898\n",
      "Iter: 14: Score: 1.3422420815510656\n",
      "Iter: 15: Score: 1.3421743221294884\n",
      "Iter: 16: Score: 1.3419755577852146\n",
      "Iter: 17: Score: 1.3423722814458972\n",
      "Iter: 18: Score: 1.3421461338643188\n",
      "Iter: 19: Score: 1.342591735406409\n",
      "Iter: 20: Score: 1.3419262132691203\n",
      "Iter: 21: Score: 1.3418827312348398\n",
      "Iter: 22: Score: 1.3419525857463248\n",
      "Iter: 23: Score: 1.3436988342876024\n",
      "Iter: 24: Score: 1.3421160874305798\n",
      "{'n_estimators': 100, 'min_weight_fraction_leaf': 0.005, 'max_features': 1, 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [05:52, 70.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95292, 13) (10580, 13)\n",
      "Iter: 0: Score: 1.305711155937452\n",
      "Iter: 1: Score: 1.3057110930031801\n",
      "Iter: 2: Score: 1.3059276140234957\n",
      "Iter: 3: Score: 1.3060095520304322\n",
      "Iter: 4: Score: 1.305607765448201\n",
      "Iter: 5: Score: 1.306398197770949\n",
      "Iter: 6: Score: 1.3056074680999092\n",
      "Iter: 7: Score: 1.3092310560078653\n",
      "Iter: 8: Score: 1.3057712477593493\n",
      "Iter: 9: Score: 1.3057797846987753\n",
      "Iter: 10: Score: 1.305574238472711\n",
      "Iter: 11: Score: 1.3055935614363827\n",
      "Iter: 12: Score: 1.3055162881384295\n",
      "Iter: 13: Score: 1.3056847287230702\n",
      "Iter: 14: Score: 1.305824100611432\n",
      "Iter: 15: Score: 1.3060469704651052\n",
      "Iter: 16: Score: 1.3118334514664716\n",
      "Iter: 17: Score: 1.3055941625643053\n",
      "Iter: 18: Score: 1.3058402046902113\n",
      "Iter: 19: Score: 1.3055445358112618\n",
      "Iter: 20: Score: 1.3061756761081125\n",
      "Iter: 21: Score: 1.3057385560238517\n",
      "Iter: 22: Score: 1.3076844132634111\n",
      "Iter: 23: Score: 1.3104996172742118\n",
      "Iter: 24: Score: 1.3055953513471776\n",
      "{'n_estimators': 300, 'min_weight_fraction_leaf': 0.02, 'max_features': 'sqrt', 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [08:00, 68.70s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "scores = []\n",
    "for train, test in tqdm(get_cv_splits(X, split_length=252*3)):\n",
    "    # break out X and y train, test\n",
    "    X_train, y_train = train[features], train[target] \n",
    "    X_test, y_test = test[features], test[target]\n",
    "\n",
    "    # hyper-param loop\n",
    "    X_train2, X_val, y_train2, y_val = train_val_split(X_train, y_train)\n",
    "    print(X_train2.shape, X_val.shape)\n",
    "\n",
    "    # inner loop for parameter tuning\n",
    "    gscv_scores = {'scores': [], 'grid':[]}\n",
    "    for k, p in enumerate(params):\n",
    "        model = RandomForestRegressor(**p)\n",
    "        model.n_jobs=-1\n",
    "        model.fit(X_train2, y_train2.values.reshape(y_train2.shape[0], ))\n",
    "        _pred = model.predict(X_val)\n",
    "        _score = mean_squared_error(y_val, _pred)\n",
    "        gscv_scores['scores'].append(_score)\n",
    "        gscv_scores['grid'].append(p)\n",
    "        print(f'Iter: {k}: Score: {_score}')\n",
    "\n",
    "    # now fit the best model\n",
    "    best_model = pd.DataFrame(gscv_scores).sort_values(by='scores').head(1)['grid'].values[0]\n",
    "    print(best_model)\n",
    "    best_model = RandomForestRegressor(**best_model)\n",
    "    best_model.n_jobs=-1\n",
    "    best_model.fit(X_train, y_train.values.reshape(y_train.shape[0], ))\n",
    "    preds = best_model.predict(X_test)\n",
    "\n",
    "    # append the predictions\n",
    "    predictions.append(pd.Series(index=y_test.index, data=preds))\n",
    "\n",
    "    # score\n",
    "    scores.append(mean_squared_error(y_test, preds))\n",
    "\n",
    "# predictions\n",
    "predictions = pd.concat(predictions).to_frame(\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we join the forecasted returns back into the returns df, we can create a simple portfolio construction strategy where we equal weight the top half, top quartile of the clusters. We can also create a long short strategy that goes long the top quartile of forecasting cluster returns and short the bottom quartile, for a market neutral portfolio.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = load_features_data()\n",
    "predictions=predictions.join(all_feats[['1d_ret']])\n",
    "\n",
    "predictions['signal_quintile']=predictions.groupby(by='date')['predictions'].apply(lambda x: pd.qcut(x, 5, labels=False)).droplevel(0)\n",
    "predictions['signal_quintiles_shift'] = predictions.groupby(by='cluster')['signal_quintile'].shift(1)\n",
    "(1+predictions.groupby(by=['date', 'signal_quintiles_shift'])['1d_ret'].mean().unstack()).cumprod().plot(title=\"Forecasted by Cluster Quintile\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
