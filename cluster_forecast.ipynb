{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, LassoCV, ElasticNetCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from utils.ml_utils import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_prep import load_features_data\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the features data, these are popular trend following features used in prior literature, this notebook assumes you have the pickle file residual_returns.pkl saved in the root directory, you can download this file from the OneDrive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ret</th>\n",
       "      <th>rVol</th>\n",
       "      <th>1d_ret</th>\n",
       "      <th>1wk_ret</th>\n",
       "      <th>1m_ret</th>\n",
       "      <th>1Q_ret</th>\n",
       "      <th>6M_ret</th>\n",
       "      <th>12M_ret</th>\n",
       "      <th>feature_1d_ra</th>\n",
       "      <th>feature_1wk_ra</th>\n",
       "      <th>...</th>\n",
       "      <th>lag5_feature_MACD_short</th>\n",
       "      <th>lag5_feature_MACD_medium</th>\n",
       "      <th>lag5_feature_MACD_long</th>\n",
       "      <th>lag5_feature_skew6m</th>\n",
       "      <th>lag5_feature_skew12m</th>\n",
       "      <th>lag5_feature_kurt6m</th>\n",
       "      <th>lag5_feature_kurt12m</th>\n",
       "      <th>fwd_ret1d</th>\n",
       "      <th>target</th>\n",
       "      <th>targetBin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2024-03-15</th>\n",
       "      <th>15</th>\n",
       "      <td>3.398228</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>-0.018600</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.003738</td>\n",
       "      <td>-0.010729</td>\n",
       "      <td>0.088150</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>-1.725280</td>\n",
       "      <td>-0.447788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138748</td>\n",
       "      <td>0.259889</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>-0.202834</td>\n",
       "      <td>-0.023611</td>\n",
       "      <td>0.229975</td>\n",
       "      <td>0.324046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.080426</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>-0.020717</td>\n",
       "      <td>-0.020520</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.084058</td>\n",
       "      <td>-0.022932</td>\n",
       "      <td>-1.884206</td>\n",
       "      <td>-0.834625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>0.322557</td>\n",
       "      <td>0.642906</td>\n",
       "      <td>-0.195628</td>\n",
       "      <td>-0.024484</td>\n",
       "      <td>0.209541</td>\n",
       "      <td>0.330980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.019482</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>-0.018740</td>\n",
       "      <td>-0.010313</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>-0.059504</td>\n",
       "      <td>-0.079410</td>\n",
       "      <td>-0.113126</td>\n",
       "      <td>-1.689814</td>\n",
       "      <td>-0.415871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101396</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>-0.415118</td>\n",
       "      <td>-0.213701</td>\n",
       "      <td>-0.034735</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.327998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.257413</td>\n",
       "      <td>0.011017</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>-0.005898</td>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.064581</td>\n",
       "      <td>0.131315</td>\n",
       "      <td>0.153882</td>\n",
       "      <td>-1.285637</td>\n",
       "      <td>-0.239423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483758</td>\n",
       "      <td>0.557877</td>\n",
       "      <td>0.717302</td>\n",
       "      <td>-0.229808</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>0.153079</td>\n",
       "      <td>0.316662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.623791</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.111935</td>\n",
       "      <td>0.238240</td>\n",
       "      <td>0.080132</td>\n",
       "      <td>0.179593</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173823</td>\n",
       "      <td>0.503369</td>\n",
       "      <td>0.849991</td>\n",
       "      <td>-0.236460</td>\n",
       "      <td>-0.033288</td>\n",
       "      <td>0.163940</td>\n",
       "      <td>0.359519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ret      rVol    1d_ret   1wk_ret    1m_ret  \\\n",
       "date       cluster                                                      \n",
       "2024-03-15 15        3.398228  0.010781 -0.018600 -0.010795 -0.003738   \n",
       "           16        3.080426  0.010995 -0.020717 -0.020520 -0.008363   \n",
       "           17        4.019482  0.011090 -0.018740 -0.010313  0.002589   \n",
       "           18       10.257413  0.011017 -0.014164 -0.005898  0.047696   \n",
       "           19        3.623791  0.010924  0.001962  0.001796  0.001793   \n",
       "\n",
       "                      1Q_ret    6M_ret   12M_ret  feature_1d_ra  \\\n",
       "date       cluster                                                \n",
       "2024-03-15 15      -0.010729  0.088150  0.044806      -1.725280   \n",
       "           16       0.004148  0.084058 -0.022932      -1.884206   \n",
       "           17      -0.059504 -0.079410 -0.113126      -1.689814   \n",
       "           18       0.064581  0.131315  0.153882      -1.285637   \n",
       "           19       0.111935  0.238240  0.080132       0.179593   \n",
       "\n",
       "                    feature_1wk_ra  ...  lag5_feature_MACD_short  \\\n",
       "date       cluster                  ...                            \n",
       "2024-03-15 15            -0.447788  ...                 0.138748   \n",
       "           16            -0.834625  ...                 0.097605   \n",
       "           17            -0.415871  ...                 0.101396   \n",
       "           18            -0.239423  ...                 0.483758   \n",
       "           19             0.073513  ...                 0.173823   \n",
       "\n",
       "                    lag5_feature_MACD_medium  lag5_feature_MACD_long  \\\n",
       "date       cluster                                                     \n",
       "2024-03-15 15                       0.259889                0.574767   \n",
       "           16                       0.322557                0.642906   \n",
       "           17                       0.006033               -0.415118   \n",
       "           18                       0.557877                0.717302   \n",
       "           19                       0.503369                0.849991   \n",
       "\n",
       "                    lag5_feature_skew6m  lag5_feature_skew12m  \\\n",
       "date       cluster                                              \n",
       "2024-03-15 15                 -0.202834             -0.023611   \n",
       "           16                 -0.195628             -0.024484   \n",
       "           17                 -0.213701             -0.034735   \n",
       "           18                 -0.229808             -0.042143   \n",
       "           19                 -0.236460             -0.033288   \n",
       "\n",
       "                    lag5_feature_kurt6m  lag5_feature_kurt12m  fwd_ret1d  \\\n",
       "date       cluster                                                         \n",
       "2024-03-15 15                  0.229975              0.324046        NaN   \n",
       "           16                  0.209541              0.330980        NaN   \n",
       "           17                  0.168224              0.327998        NaN   \n",
       "           18                  0.153079              0.316662        NaN   \n",
       "           19                  0.163940              0.359519        NaN   \n",
       "\n",
       "                    target  targetBin  \n",
       "date       cluster                     \n",
       "2024-03-15 15          NaN        NaN  \n",
       "           16          NaN        NaN  \n",
       "           17          NaN        NaN  \n",
       "           18          NaN        NaN  \n",
       "           19          NaN        NaN  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = load_features_data()\n",
    "feats.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    125019.000000\n",
      "mean          0.029297\n",
      "std           1.228097\n",
      "min         -18.536928\n",
      "25%          -0.597784\n",
      "50%           0.062029\n",
      "75%           0.686203\n",
      "max          70.166324\n",
      "Name: target, dtype: float64\n",
      "count    125019.000000\n",
      "mean          0.028428\n",
      "std           1.201198\n",
      "min         -10.000000\n",
      "25%          -0.597784\n",
      "50%           0.062029\n",
      "75%           0.686203\n",
      "max          10.000000\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGxCAYAAACju/aQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAy+0lEQVR4nO3dfVzUZb7/8fcwwIAIpKLcqMkomhW4GpV3UZBplnoiQt2othsrO2atpZthvzX1FHSDbj0yTa3stKVpxlrZnWyZUbJmdrTQbtTETCBMPUCKoDPf3x8dZh3B0gTmAl7Px2Mey1zfa77zmcFt3lzf67rGZlmWJQAAAEP5+boAAACAX0NYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlhBq/PCCy/IZrN53Tp27Kjk5GStWrWqyev58MMPvWqx2+2KjIzU6NGj9dVXX3n6FRUVyWaz6YUXXjjl59i6datmzJihoqKihiv8/7z//vs6//zzFRISIpvNppUrV9bpk5ycXOc9r+82Y8aMBq/vdBw6dEgzZszQhx9++Jt9n3zySdlsNr377rsn7LNo0SLZbDbl5uY2SH2xsbG66aabftdjbTabJk6c+Jv9av99nsx7ADQWf18XAPjK4sWL1bt3b1mWpdLSUs2dO1ejRo3SG2+8oVGjRjV5PVlZWUpJSVFNTY0+++wzzZo1S++//76+/PJLde7c+bTOvXXrVs2cOVPJycmKjY1tmIIlWZalMWPGqFevXnrjjTcUEhKis846q06/efPmqaKiwnP/rbfe0kMPPeT5HdTq0qVLg9XWEA4dOqSZM2dK+iVw/Zrrr79eU6dO1fPPP6/hw4fX22fx4sXq2LFjg/37+sc//qGwsLAGORdgMsIKWq34+Hidf/75nvvDhw9Xu3bttHTpUp+ElZ49e2rAgAGSpIsvvlhnnHGGxo0bpxdeeEEPPPBAk9dzMoqLi7V//35dffXVGjJkyAn7nXPOOV73v/76a0l1fwe/16FDh9SmTZvTPs/p6NChg6666iqtXLlS+/btU4cOHbyOf/311yooKNDkyZMVEBBwWs9VVVWl4OBg9evX77TOAzQXXAYC/k9QUJACAwPrfJDs379fEyZMUOfOnRUYGKju3bvrgQceUHV1tSTp8OHD6tevn+Li4lReXu55XGlpqaKiopScnCyXy3XK9dQGl127dv1qv48//lhDhgxRaGio2rRpo0GDBumtt97yHH/hhRc0evRoSVJKSornkstvXU76rfPOmDHDMxIydepU2Wy20xq1ycvL01VXXaUuXbooKChIcXFxGj9+vH766SevfjNmzJDNZtPnn3+u9PR0tWvXTj169JAkVVdXa/LkyYqKilKbNm108cUXa+PGjfVeLiktLdX48ePVpUsXBQYGyul0aubMmTp69KikXy67dezYUZI0c+ZMz/v2a5ddxo0bp5qaGi1ZsqTOscWLF0uSbrnlFs85+/fvr/bt2yssLEznnXeennvuOR3/3bKxsbEaOXKkcnNz1a9fPwUFBXlGe45/XYcPH9bkyZPVt29fhYeHq3379ho4cKBef/31E9a8YMEC9erVSw6HQ+ecc45eeeWVE/Y91meffab/+I//UPv27RUUFKR+/fpp+fLlJ/VY4FQxsoJWy+Vy6ejRo7IsSz/++KMef/xxHTx4UBkZGZ4+hw8fVkpKinbs2KGZM2eqT58+ys/PV3Z2tjZt2qS33npLQUFBWr58uRITE3XLLbfotddek9vt1nXXXSfLsrR06VLZ7fZTrm/79u2S5PnArM/atWs1dOhQ9enTR88995wcDofmzZunUaNGaenSpRo7dqxGjBihrKwsTZs2TU8//bTOO+88SfJ8wP/e89566636wx/+oLS0NN11113KyMiQw+E45ddZa8eOHRo4cKBuvfVWhYeHq6ioSHPmzNFFF12kL7/8sk6ITEtL0x//+EfdcccdOnjwoCTp5ptv1rJly3Tffffp0ksv1datW3X11Vd7XYKSfgkqF154ofz8/DR9+nT16NFDBQUFeuihh1RUVKTFixcrOjpa7777roYPH65x48bp1ltvlfTrv4/LLrtM3bp10/PPP6+77rrL0+5yufT3v/9dAwYM8IwyFRUVafz48TrzzDMlSf/617901113ac+ePZo+fbrXeT///HN99dVX+n//7//J6XQqJCSk3uevrq7W/v37NWXKFHXu3Fk1NTX65z//qbS0NC1evFh/+tOfvPq/8cYbWrNmjWbNmqWQkBDNmzdP1157rfz9/ZWenn7C17lmzRoNHz5c/fv31zPPPKPw8HC98sorGjt2rA4dOvS759EAJ2QBrczixYstSXVuDofDmjdvnlffZ555xpJkLV++3Kv90UcftSRZq1ev9rQtW7bMkmQ98cQT1vTp0y0/Pz+v4yeyZs0aS5K1bNky68iRI9ahQ4esjz76yIqLi7Psdru1efNmy7Isa+fOnZYka/HixZ7HDhgwwOrUqZNVWVnpaTt69KgVHx9vdenSxXK73ZZlWdarr75qSbLWrFlzUu/RyZ63tqbHH3/8pM5bq/Z3sGHDhnqPu91u68iRI9auXbssSdbrr7/uOfbggw9akqzp06d7PWbLli2WJGvq1Kle7UuXLrUkWTfeeKOnbfz48Vbbtm2tXbt2efXNycmxJFlbtmyxLMuy9u7da0myHnzwwZN+bbX1ff755562N99805JkLVq0qN7HuFwu68iRI9asWbOsDh06eN5fy7Ksbt26WXa73frmm2/qPK5bt25er+t4R48etY4cOWKNGzfO6tevn9cxSVZwcLBVWlrq1b93795WXFycp6323+ex/3Z69+5t9evXzzpy5IjXOUeOHGlFR0dbLpfrhDUBvweXgdBqvfjii9qwYYM2bNigd955RzfeeKPuvPNOzZ0719Pngw8+UEhISJ2/Mmv/cnz//fc9bWPGjNF//ud/6i9/+YseeughTZs2TUOHDj3pesaOHauAgADP5QuXy6UVK1aoT58+9fY/ePCg1q9fr/T0dLVt29bTbrfbdcMNN+iHH37QN998c9LP39jn/S1lZWW644471LVrV/n7+ysgIEDdunWTJK9VUbWuueYar/tr166V9Mvv4Vjp6eny9/ceRF61apVSUlIUExOjo0ePem5XXHGF17l+j5tvvll+fn56/vnnPW2LFy9WSEiIxo4d62n74IMPdNlllyk8PFx2u10BAQGaPn269u3bp7KyMq9z9unTR7169Tqp53/11Vc1ePBgtW3b1vM+Pvfcc/W+h0OGDFFkZKTnvt1u19ixY7V9+3b98MMP9Z5/+/bt+vrrr3XddddJktf7d+WVV6qkpKRR/n2gdeMyEFqts88+u84E2127dum+++7T9ddfrzPOOEP79u1TVFSUbDab12M7deokf39/7du3z6v9lltu0fz58xUYGKi77777lOp59NFHdemll8putysiIkJdu3b91f4HDhyQZVmKjo6ucywmJkaS6tR3MhrrvL/G7XZr2LBhKi4u1l//+lclJCQoJCREbrdbAwYMUFVVVZ3HHF9fbU3HfvhKkr+/f53Jrj/++KPefPPNE050PX6ezKno1q2bhgwZoiVLlignJ0eVlZVatWqVMjIyFBoaKkn69NNPNWzYMCUnJ2vRokWeeTMrV67Uww8/XOf11ve7qE9ubq7GjBmj0aNH6y9/+YuioqLk7++v+fPne4WnWlFRUSds27dvX72rs3788UdJ0pQpUzRlypR66zid9w+oD2EFOEafPn303nvv6dtvv9WFF16oDh06aP369bIsyyuwlJWV6ejRo4qIiPC0HTx4UDfccIN69eqlH3/8UbfeeuuvTmw8Xvfu3U9pZUy7du3k5+enkpKSOseKi4slyas+X5/31xQWFmrz5s164YUXdOONN3raa+ft1Of4AFkbSH788Uevpd5Hjx6tE64iIiLUp08fPfzww/WeuzaU/V7jxo1TXl6eXn/9dRUXF6umpkbjxo3zHH/llVcUEBCgVatWKSgoyNNe3x41Ut3XeiIvvfSSnE6nli1b5vWY2sngxystLT1h2/EBr1bt7z4zM1NpaWn19qlv+TpwOggrwDE2bdok6d+TKIcMGaLly5dr5cqVuvrqqz39XnzxRc/xWnfccYe+//57ffrpp/r666+Vnp6uv/3tb7rnnnsapdaQkBD1799fubm5ysnJUXBwsKRfRileeukldenSxXPpoHbia30jFKdz3oZS+8F6/ATdBQsWnPQ5Lr74YknSsmXLPJOIJWnFihWeFT61Ro4cqbfffls9evRQu3btTnjOU3nfjpWamqoOHTro+eefV0lJiXr16qWLLrrIc9xms8nf399r4nVVVZX+/ve/n9LzHM9msykwMNArqJSWlp4wNL///vv68ccfPaNRLpdLy5YtU48ePU64581ZZ52lnj17avPmzcrKyjqteoGTRVhBq1VYWOj5ENu3b59yc3OVl5enq6++Wk6nU5L0pz/9SU8//bRuvPFGFRUVKSEhQR9//LGysrJ05ZVX6rLLLpMkPfvss3rppZe0ePFinXvuuTr33HM1ceJETZ06VYMHD9aFF17YKK8hOztbQ4cOVUpKiqZMmaLAwEDNmzdPhYWFWrp0qedDKz4+XpK0cOFChYaGKigoSE6n84R/PZ/seRtK79691aNHD91///2yLEvt27fXm2++qby8vJM+x7nnnqtrr71Ws2fPlt1u16WXXqotW7Zo9uzZCg8Pl5/fv6fozZo1S3l5eRo0aJDuvvtunXXWWTp8+LCKior09ttv65lnnlGXLl0UGhqqbt266fXXX9eQIUPUvn17RURE/OYSbYfDoeuuu05PPfWULMvSI4884nV8xIgRmjNnjjIyMnT77bdr3759ysnJOa3VVJI8S5wnTJig9PR07d69W//1X/+l6Ohobdu2rU7/iIgIXXrppfrrX//qWQ309ddf/+by5QULFuiKK67Q5ZdfrptuukmdO3fW/v379dVXX+nzzz/Xq6++elqvA6jDp9N7AR+obzVQeHi41bdvX2vOnDnW4cOHvfrv27fPuuOOO6zo6GjL39/f6tatm5WZmenp98UXX1jBwcF1VmUcPnzYSkxMtGJjY60DBw6csJ7a1Ravvvrqr9Zd32ogy7Ks/Px869JLL7VCQkKs4OBga8CAAdabb75Z5/FPPPGE5XQ6LbvdXu95jncy523I1UBbt261hg4daoWGhlrt2rWzRo8ebX3//fd1VuPUrrbZu3dvnfMePnzYuvfee61OnTpZQUFB1oABA6yCggIrPDzcuueee7z67t2717r77rstp9NpBQQEWO3bt7cSExOtBx54wPr55589/f75z39a/fr1sxwOR51VRb9m8+bNliTLbrdbxcXFdY4///zz1llnnWU5HA6re/fuVnZ2tvXcc89ZkqydO3d6+nXr1s0aMWJEvc9R32qgRx55xIqNjbUcDod19tlnW4sWLfK8Z8eSZN15553WvHnzrB49elgBAQFW7969rZdfftmrX32rgWpf35gxY6xOnTpZAQEBVlRUlHXppZdazzzzzEm9P8CpsFnWcTsQAUALsm7dOg0ePFgvv/yy1x46AJoPwgqAFiMvL08FBQVKTExUcHCwNm/erEceeUTh4eH64osvvCazAmg+mLMCoMUICwvT6tWr9cQTT6iyslIRERG64oorlJ2dTVABmjFGVgAAgNHYwRYAABiNsAIAAIxGWAEAAEZr9hNs3W63iouLFRoa2uAbVQEAgMZhWZYqKysVExPjtWljfZp9WCkuLv7NL3wDAABm2r179wm/3qFWsw8rtd9iunv3boWFhfm4GgAAcDIqKirUtWtXz+f4r2n2YaX20k9YWBhhBQCAZuZkpnAwwRYAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMFqz3xQOQMvkcrmUn5+vkpISRUdHKykpSXa73ddlAfABRlYAGCc3N1dxcXFKSUlRRkaGUlJSFBcXp9zcXF+XBsAHCCsAjJKbm6v09HQlJCSooKBAlZWVKigoUEJCgtLT0wksQCtksyzL8nURp6OiokLh4eEqLy/nu4GAZs7lcikuLk4JCQlauXKl19fGu91upaamqrCwUNu2beOSENDMncrnNyMrAIyRn5+voqIiTZs2zSuoSJKfn58yMzO1c+dO5efn+6hCAL5AWAFgjJKSEklSfHx8vcdr22v7AWgdCCsAjBEdHS1JKiwsrPd4bXttPwCtA2EFgDGSkpIUGxurrKwsud1ur2Nut1vZ2dlyOp1KSkryUYUAfIGwAsAYdrtds2fP1qpVq5Samuq1Gig1NVWrVq1STk4Ok2uBVoZN4QAYJS0tTStWrNDkyZM1aNAgT7vT6dSKFSuUlpbmw+oA+AJLlwEYiR1sgZbtVD6/GVkBYCS73a7k5GRflwHAAMxZAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGA0wgoAADAaYQUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaI0eVvbs2aPrr79eHTp0UJs2bdS3b19t3LjRc9yyLM2YMUMxMTEKDg5WcnKytmzZ0thlAQCAZqJRw8qBAwc0ePBgBQQE6J133tHWrVs1e/ZsnXHGGZ4+jz32mObMmaO5c+dqw4YNioqK0tChQ1VZWdmYpQEAgGbCZlmW1Vgnv//++/XJJ58oPz+/3uOWZSkmJkaTJk3S1KlTJUnV1dWKjIzUo48+qvHjx//mc1RUVCg8PFzl5eUKCwtr0PoBAEDjOJXP70YdWXnjjTd0/vnna/To0erUqZP69eunRYsWeY7v3LlTpaWlGjZsmKfN4XDokksu0bp16+o9Z3V1tSoqKrxuAACg5WrUsPLdd99p/vz56tmzp9577z3dcccduvvuu/Xiiy9KkkpLSyVJkZGRXo+LjIz0HDtedna2wsPDPbeuXbs25ksAAAA+1qhhxe1267zzzlNWVpb69eun8ePH67bbbtP8+fO9+tlsNq/7lmXVaauVmZmp8vJyz2337t2NVj8AAPC9Rg0r0dHROuecc7zazj77bH3//feSpKioKEmqM4pSVlZWZ7SllsPhUFhYmNcNAAC0XI0aVgYPHqxvvvnGq+3bb79Vt27dJElOp1NRUVHKy8vzHK+pqdHatWs1aNCgxiwNAAA0E/6NefJ77rlHgwYNUlZWlsaMGaNPP/1UCxcu1MKFCyX9cvln0qRJysrKUs+ePdWzZ09lZWWpTZs2ysjIaMzSAABAM9GoYeWCCy7QP/7xD2VmZmrWrFlyOp164okndN1113n63HfffaqqqtKECRN04MAB9e/fX6tXr1ZoaGhjlgYAAJqJRt1npSmwzwoAAM2PMfusAAAAnC7CCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGA0wgoAADAaYQUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGA0wgoAADAaYQUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGC0Jgsr2dnZstlsmjRpkqfNsizNmDFDMTExCg4OVnJysrZs2dJUJQEAgGagScLKhg0btHDhQvXp08er/bHHHtOcOXM0d+5cbdiwQVFRURo6dKgqKyuboiwABnO5XPrwww+1dOlSffjhh3K5XL4uCYCPNHpY+fnnn3Xddddp0aJFateunafdsiw98cQTeuCBB5SWlqb4+Hj993//tw4dOqQlS5Y0dlkADJabm6u4uDilpKQoIyNDKSkpiouLU25urq9LA+ADjR5W7rzzTo0YMUKXXXaZV/vOnTtVWlqqYcOGedocDocuueQSrVu37oTnq66uVkVFhdcNQMuRm5ur9PR0JSQkqKCgQJWVlSooKFBCQoLS09MJLEAr1Khh5ZVXXtHnn3+u7OzsOsdKS0slSZGRkV7tkZGRnmP1yc7OVnh4uOfWtWvXhi0agM+4XC5NnjxZI0eO1MqVKzVgwAC1bdtWAwYM0MqVKzVy5EhNmTKFS0JAK9NoYWX37t3685//rJdeeklBQUEn7Gez2bzuW5ZVp+1YmZmZKi8v99x2797dYDUD8K38/HwVFRVp2rRp8vPz/s+Tn5+fMjMztXPnTuXn5/uoQgC+4N9YJ964caPKysqUmJjoaXO5XProo480d+5cffPNN5J+GWGJjo729CkrK6sz2nIsh8Mhh8PRWGUD8KGSkhJJUnx8fL3Ha9tr+wFoHRptZGXIkCH68ssvtWnTJs/t/PPP13XXXadNmzape/fuioqKUl5enucxNTU1Wrt2rQYNGtRYZQEwWO0fLoWFhfUer20/9g8cAC1fo42shIaG1vnrKCQkRB06dPC0T5o0SVlZWerZs6d69uyprKwstWnTRhkZGY1VFgCDJSUlKTY2VllZWVq5cqXXpSC3263s7Gw5nU4lJSX5sEoATa3RwsrJuO+++1RVVaUJEybowIED6t+/v1avXq3Q0FBflgXAR+x2u2bPnq309HSlpqYqMzNT8fHxKiwsVHZ2tlatWqUVK1bIbrf7ulQATchmWZbl6yJOR0VFhcLDw1VeXq6wsDBflwOgAeTm5mry5MkqKirytDmdTuXk5CgtLc13hQFoMKfy+U1YAWAkl8ul/Px8lZSUKDo6WklJSYyoAC3IqXx++/QyEACciN1uV3Jysq/LAGAAvnUZAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGA0wgoAADAaYQUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGA0wgoAADAaYQUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYzd/XBQBAfVwul/Lz81VSUqLo6GglJSXJbrf7uiwAPsDICgDj5ObmKi4uTikpKcrIyFBKSori4uKUm5vr69IA+ABhBYBRcnNzlZ6eroSEBBUUFKiyslIFBQVKSEhQeno6gQVohWyWZVm+LuJ0VFRUKDw8XOXl5QoLC/N1OQBOg8vlUlxcnBISErRy5Ur5+f377ym3263U1FQVFhZq27ZtXBICmrlT+fxmZAWAMfLz81VUVKRp06Z5BRVJ8vPzU2Zmpnbu3Kn8/HwfVQjAFwgrAIxRUlIiSYqPj6/3eG17bT8ArQNhBYAxoqOjJUmFhYX1Hq9tr+0HoHUgrAAwRlJSkmJjY5WVlSW32+11zO12Kzs7W06nU0lJST6qEIAvEFYAGMNut2v27NlatWqVUlNTvVYDpaamatWqVcrJyWFyLdDKsCkcAKOkpaVpxYoVmjx5sgYNGuRpdzqdWrFihdLS0nxYHQBfYOkyACOxgy3Qsp3K5zcjKwCMZLfblZyc7OsyABiAOSsAAMBohBUAAGC0Rg0r2dnZuuCCCxQaGqpOnTopNTVV33zzjVcfy7I0Y8YMxcTEKDg4WMnJydqyZUtjlgUAAJqRRg0ra9eu1Z133ql//etfysvL09GjRzVs2DAdPHjQ0+exxx7TnDlzNHfuXG3YsEFRUVEaOnSoKisrG7M0AADQTDTpaqC9e/eqU6dOWrt2rS6++GJZlqWYmBhNmjRJU6dOlSRVV1crMjJSjz76qMaPH/+b52Q1EAAAzY+xX2RYXl4uSWrfvr0kaefOnSotLdWwYcM8fRwOhy655BKtW7eu3nNUV1eroqLC6wYAAFquJgsrlmXp3nvv1UUXXeT5MrLS0lJJUmRkpFffyMhIz7HjZWdnKzw83HPr2rVr4xYOAAB8qsnCysSJE/XFF19o6dKldY7ZbDav+5Zl1WmrlZmZqfLycs9t9+7djVIvAAAwQ5NsCnfXXXfpjTfe0EcffaQuXbp42qOioiT9MsJy7LeolpWV1RltqeVwOORwOBq3YAAAYIxGHVmxLEsTJ05Ubm6uPvjgAzmdTq/jTqdTUVFRysvL87TV1NRo7dq1Xt8JAgAAWq9GHVm58847tWTJEr3++usKDQ31zEMJDw9XcHCwbDabJk2apKysLPXs2VM9e/ZUVlaW2rRpo4yMjMYsDQAANBONGlbmz58vSXW+32Px4sW66aabJEn33XefqqqqNGHCBB04cED9+/fX6tWrFRoa2pilAQCAZoJvXQYAAE3O2H1WAAAAThVhBQAAGI2wAgAAjEZYAQAARiOsAAAAozXJDrYAcKpcLpfy8/NVUlKi6OhoJSUlyW63+7osAD7AyAoA4+Tm5iouLk4pKSnKyMhQSkqK4uLilJub6+vSAPgAYQWAUXJzc5Wenq6EhAQVFBSosrJSBQUFSkhIUHp6OoEFaIXYFA6AMVwul+Li4pSQkKDXXntNn3zyiecy0ODBg3XNNdeosLBQ27Zt45IQ0MyxKRyAZik/P19FRUUaNGiQevXq5XUZqFevXho4cKB27typ/Px8X5cKoAkxwRaAMUpKSiRJmZmZGjFihK666ipVVVUpODhY27dv17Rp07z6AWgdCCsAjNGpUydJUufOnfXuu+/K5XJ5jtntdnXu3Fl79uzx9APQOnAZCIBx9uzZow4dOmjRokUqKSnRokWL1KFDB+3Zs8fXpQHwAcIKAGMUFxd7fr7gggtUXV2tt99+W9XV1brgggvq7Qeg5eMyEABjrF+/XpJ04YUX6r333tNbb73lOebv768LLrhAGzZs0Pr163XDDTf4qkwATYywAsAYtTspfPrpp7ryyivVs2dPzwTbbdu26e233/bqB6B1IKwAMEb37t09P3/wwQeecCJJQUFB9fYD0PIxZwWAMRISEk54zGaznVQ/AC0PIysAjLF3717Pz2FhYRo1apRCQkJ08OBBrV27VlVVVXX6AWj5CCsAjFEbQvr27atNmzbp1Vdf9Tr+hz/8QZs3byasAK0Ml4EAGKNjx46SpE2bNnnNUZF+mbOyefNmr34AWgdGVgAYIyoqyvNzWFiYBgwYILfbLT8/P23dulWHDx+u0w9Ay0dYAWCM2u317Xa7ysrKVFZW5nXcbrfL5XJ5bcMPoOXjMhAAY9R+m3JtGElMTNTYsWOVmJjo1c63LgOtCyMrAIxx5MgRSf9eprxx40Zt3LhRkuTn5yfLsmRZlqcfgNaBsALAGF999ZWkX3aoveKKK9SmTRsdOHBA7dq106FDh/TOO+949QPQOhBWABjj0KFDnp9rg8lv9QPQ8jFnBYAx2rZt26D9ALQMhBUAxhg5cqTnZ7vd7nXs2PvH9gPQ8hFWABjjf/7nfzw/H788+dj7x/YD0PIRVgAYw+12N2g/AC0DYQWAMSzL8rofEBCgtm3bKiAg4Ff7AWjZWA0EwBgOh8Pr/pEjR+rdU+X4fgBaNkZWABjj5ZdfbtB+AFoGwgoAY1RVVTVoPwAtA2EFgDGOX658uv0AtAyEFQDGaN++fYP2A9AyEFYAGGPv3r0N2g9Ay0BYAWCMmpqaBu0HoGUgrAAwBpvCAagPYQWAMY7fYv90+wFoGQgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAAGA0wgoAADAaYQUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNH8fV0AgJalqsalHXt/bvTnKdxT/rse16NjWwUH2hu4GgCNibACoEHt2PuzRj71caM/z+99jlV3XaT4zuENXA2AxmSzLMvydRGno6KiQuHh4SovL1dYWJivywFavdMZWUnocsZJ9/3yh//9Xc/ByApghlP5/GZkBUCDCg60N8nIBaMjQOvBBFsAxjjZgd5mPiAM4BQRVgAY5beCCEEFaH0IKwCMc6JAQlABWicjwsq8efPkdDoVFBSkxMRE5efn+7okAD5mWZa+/OF/1W3qKn35w/8SVIBWzOcTbJctW6ZJkyZp3rx5Gjx4sBYsWKArrrhCW7du1Zlnnunr8oBWZedPB3Ww+qivy/DYXvaz1/+aIsThL2dEiK/LAFoNny9d7t+/v8477zzNnz/f03b22WcrNTVV2dnZv/l4li4DDWPnTweVkvOhr8toNtZMSSawAKeh2Sxdrqmp0caNG3X//fd7tQ8bNkzr1q2r9zHV1dWqrq723K+oqGjUGoHWYv+hn+UXtEdThvZS1/ZtfF2OJKn6qFtlFYfVKSxIDn8jrlpr9/5Dysn7VvsP/SynCCtAU/BpWPnpp5/kcrkUGRnp1R4ZGanS0tJ6H5Odna2ZM2c2RXlAq1J8cJdCnE9p/nZfV2K+EKdUfLCvEhX5250BnDafz1mRJJvN5nXfsqw6bbUyMzN17733eu5XVFSoa9eujVof0BrEhHTTwZ136cmxfdWjU1tfl2OsHWU/68/LNikmpZuvSwFaDZ+GlYiICNnt9jqjKGVlZXVGW2o5HA45HI6mKA9oVdzuALkPd9bByii5w8zYHfbwEZd+OFClLu2CFRRgxhb5rsM/y314rxz2IF+XArQaPg0rgYGBSkxMVF5enq6++mpPe15enq666iofVga0Pjv+b8XN/blf+riS5iHEYcTANNAq+Pz/bffee69uuOEGnX/++Ro4cKAWLlyo77//XnfccYevSwNalWHnRkmSenRqq2BDRjG2l/2sScs26YmxfRVn0KUpli4DTcvnYWXs2LHat2+fZs2apZKSEsXHx+vtt99Wt25cDwaaUvuQQP3xQnP2Njp23trVj/7yv2wMB7ROPt9n5XSxzwrQ8pxogr1EYAFailP5/DZj4wIA+D+/FlRO5jiAloewAsAYJxtECCxA6+LzOSsAWpaqGpd27G387/Ip3FP+ux7Xo2NbBQeaMYEYwMkhrABoUDv2/qyRT33c6M/ze59j1V0XKb6zGfvIADg5TLAF0KBOZ2QlocsZJ933yx/+93c9ByMrgBmazRcZAmh5ggPtTTJywegI0HowwRYAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAAwGiEFQAAYDTCCgAAMBphBQAAGI2wAgAAjEZYAQAARiOsAAAAoxFWAACA0QgrAADAaIQVAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBohBUAxggMDGzQfgBaBsIKAGP06tWrQfsBaBkIKwCM4XK5GrQfgJaBsALAGAcPHmzQfgBaBsIKAGPYbLYG7QegZSCsADBGmzZtGrQfgJaBsALAGDExMQ3aD0DLQFgBYIzExMQG7QegZSCsADBGp06dGrQfgJaBsALAGFFRUQ3aD0DLQFgBYIzOnTtL+mW1T1BQkNex4OBgzyqg2n4AWgd/XxcAALWSkpIUGxsru92uXbt2eR07cuSIunfvLrfbraSkJB9VCMAXGFkBYAy73a7Ro0drx44dat++vSZPnqynn35akydPVvv27bVjxw6lp6fLbrf7ulQATchmWZbl6yJOR0VFhcLDw1VeXq6wsDBflwPgNLhcLsXFxSkiIkJ79+71Gl2JjY1VRESE9u3bp23bthFYgGbuVD6/uQwEwBj5+fkqKirS0qVLdcEFFyg/P18lJSWKjo5WUlKSPv30Uw0aNEj5+flKTk72dbkAmgiXgQAYo6SkRJIUHx9f7/Ha9tp+AFoHRlYAGCM6OlqSNHfuXC1YsEBFRUWeY7Gxsbr99tu9+gFoHRhZAWCMpKQkdezYUZmZmYqPj1dBQYEqKytVUFCg+Ph4TZs2TZ06dWI1ENDKEFYAGOXYb1S2LMtzA9B6EVYAGCM/P19lZWXKzs5WYWGhBg0apLCwMA0aNEhbtmxRVlaWysrKlJ+f7+tSATQhwgoAY9ROnJ04caK2b9+uNWvWaMmSJVqzZo22bdumiRMnevUD0DowwRaAMWonzhYWFmrAgAF1licXFhZ69QPQOrApHABj1G4Kl5CQoNdee02ffPKJZ5+VwYMH65prrlFhYSGbwgEtAJvCAWiW7Ha7Zs+erWuuuUbh4eGqqqryHAsODlZVVZVee+01ggrQyjBnBYBxjl0RdGxbfe0AWj4uAwEwBpeBgNaDy0AAmqVjvxsoICCgzgTbzMxMvhsIaIW4DATAGHw3EID6EFYAGOPYpcv1Yeky0DoRVgAYIykpSbGxscrKypLb7fY65na7lZ2dLafTyXcDAa0Mc1YAGKN26XJ6erquuuoqDR8+3LNk+d1339Vbb72lFStWMLkWaGVYDQTAOPfdd5/+9re/6ejRo542f39/3XPPPXrsscd8WBmAhsJqIADNVm5urnJycjRixAhdccUVnpGVd955Rzk5ORowYIDS0tJ8XSaAJsTICgBjHLvPysqVK+Xn9+9pdW63W6mpqeyzArQQp/L5zQRbAMao3Wdl2rRpXkFFkvz8/JSZmamdO3cqPz/fRxUC8AXCCgBjsM8KgPoQVgAYg31WANSn0cJKUVGRxo0bJ6fTqeDgYPXo0UMPPvigampqvPp9//33GjVqlEJCQhQREaG77767Th8ArQP7rACoT6OtBvr666/ldru1YMECxcXFqbCwULfddpsOHjyonJwcSb9MphsxYoQ6duyojz/+WPv27dONN94oy7L01FNPNVZpAAx17D4rqampyszMVHx8vAoLC5Wdna1Vq1axzwrQCjXpaqDHH39c8+fP13fffSdJeueddzRy5Ejt3r1bMTExkqRXXnlFN910k8rKyk5qdQ+rgYCWJzc3V5MnT1ZRUZGnzel0Kicnh2XLQAth7D4r5eXlat++ved+QUGB4uPjPUFFki6//HJVV1dr48aNSklJqXOO6upqVVdXe+5XVFQ0btEAmlxaWpquuuoq5efnq6SkRNHR0UpKSmJEBWilmiys7NixQ0899ZRmz57taSstLVVkZKRXv3bt2ikwMFClpaX1nic7O1szZ85s1FoB+J7dbldycrKvywBggFOeYDtjxgzZbLZfvX322WdejykuLtbw4cM1evRo3XrrrV7HbDZbneewLKvedknKzMxUeXm557Z79+5TfQkAAKAZOeWRlYkTJ+qPf/zjr/aJjY31/FxcXKyUlBQNHDhQCxcu9OoXFRWl9evXe7UdOHBAR44cqTPiUsvhcMjhcJxq2QAAoJk65bASERGhiIiIk+q7Z88epaSkKDExUYsXL66zI+XAgQP18MMPe65JS9Lq1avlcDiUmJh4qqUBAIAWqNFWAxUXF+uSSy7RmWeeqRdffNFrYlxUVJSkX5Yu9+3bV5GRkXr88ce1f/9+3XTTTUpNTT3ppcusBgIAoPkxYjXQ6tWrtX37dm3fvl1dunTxOlabj+x2u9566y1NmDBBgwcPVnBwsDIyMjz7sAAAAPCtywAAoMnxrcsAAKDFIKwAAACjEVYAAIDRmnS7/cZQO+WGbfcBAGg+aj+3T2bqbLMPK5WVlZKkrl27+rgSAABwqiorKxUeHv6rfZr9aiC3263i4mKFhoaecIt+AM1TRUWFunbtqt27d7PaD2hhLMtSZWWlYmJi6mwae7xmH1YAtFxsTQBAYoItAAAwHGEFAAAYjbACwFgOh0MPPvgg37QOtHLMWQEAAEZjZAUAABiNsAIAAIxGWAEAAEYjrAAAAKMRVgAAgNEIKwAaVHJysiZNmuTrMjxMqwfAqSOsADBOTU2Nr0sAYBDCCoAGc9NNN2nt2rV68sknZbPZZLPZtGPHDo0bN05Op1PBwcE666yz9OSTT9Z5XGpqqrKzsxUTE6NevXpJktatW6e+ffsqKChI559/vlauXCmbzaZNmzZ5Hrt161ZdeeWVatu2rSIjI3XDDTfop59+OmE9RUVFTfV2AGgg/r4uAEDL8eSTT+rbb79VfHy8Zs2aJUlq166dunTpouXLlysiIkLr1q3T7bffrujoaI0ZM8bz2Pfff19hYWHKy8vzfBvrqFGjdOWVV2rJkiXatWtXncs5JSUluuSSS3Tbbbdpzpw5qqqq0tSpUzVmzBh98MEH9dbTsWPHJns/ADQMwgqABhMeHq7AwEC1adNGUVFRnvaZM2d6fnY6nVq3bp2WL1/uFVZCQkL07LPPKjAwUJL0zDPPyGazadGiRQoKCtI555yjPXv26LbbbvM8Zv78+TrvvPOUlZXlaXv++efVtWtXffvtt+rVq1e99QBoXggrABrdM888o2effVa7du1SVVWVampq1LdvX68+CQkJnqAiSd9884369OmjoKAgT9uFF17o9ZiNGzdqzZo1atu2bZ3n3LFjh+dyEoDmjbACoFEtX75c99xzj2bPnq2BAwcqNDRUjz/+uNavX+/VLyQkxOu+ZVmy2Wx12o7ldrs1atQoPfroo3WeNzo6uoFeAQBfI6wAaFCBgYFyuVye+/n5+Ro0aJAmTJjgaduxY8dvnqd37956+eWXVV1d7fnW5c8++8yrz3nnnafXXntNsbGx8vev/z9nx9cDoPlhNRCABhUbG6v169erqKhIP/30k+Li4vTZZ5/pvffe07fffqu//vWv2rBhw2+eJyMjQ263W7fffru++uorvffee8rJyZEkz4jLnXfeqf379+vaa6/Vp59+qu+++06rV6/WLbfc4gkox9fjdrsb78UDaBSEFQANasqUKbLb7TrnnHPUsWNHDR8+XGlpaRo7dqz69++vffv2eY2ynEhYWJjefPNNbdq0SX379tUDDzyg6dOnS5JnHktMTIw++eQTuVwuXX755YqPj9ef//xnhYeHy8/Pr956vv/++8Z78QAahc06/iIwABjq5Zdf1s0336zy8nIFBwf7uhwATYQ5KwCM9eKLL6p79+7q3LmzNm/e7NlDhaACtC6EFQDGKi0t1fTp01VaWqro6GiNHj1aDz/8sK/LAtDEuAwEAACMxgRbAABgNMIKAAAwGmEFAAAYjbACAACMRlgBAABGI6wAAACjEVYAAIDRCCsAAMBo/x/GLBm+0iLxwgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of tragets\n",
    "feats['target'].plot(kind='box', title=\"Box Plot of Target Variable\")\n",
    "print(feats['target'].describe())\n",
    "\n",
    "# clip the three large outliers\n",
    "feats['target'] = feats['target'].clip(-10., 10.)\n",
    "print(feats['target'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feats['target'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the predictive features and target, which is one day forward risk adjusted return - drop na on this subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (119900, 79)\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in feats.columns if f.startswith(\"feature\")]\n",
    "target = [\"target\"]\n",
    "lag_feats = [f for f in feats.columns if f.startswith('lag')]\n",
    "\n",
    "# make a new feature vector for features + lags\n",
    "\n",
    "all_feats = features + lag_feats + target\n",
    "feats.dropna(subset=all_feats, inplace=True)\n",
    "feats = feats[all_feats]\n",
    "\n",
    "print(\"Shape of features\", feats.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break out X and y and set up cross-validation, define models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feats[all_feats].copy()\n",
    "\n",
    "# set some configs\n",
    "N_ITER=50\n",
    "\n",
    "# Random Forest Regressor\n",
    "baseRF = RandomForestRegressor(max_depth=5, \n",
    "                               n_estimators=1000,\n",
    "                               max_features=int(1),\n",
    "                               random_state=49, \n",
    "                               n_jobs=-1)\n",
    "\n",
    "# simple-grid\n",
    "grid = {'rf__n_estimators': np.arange(100, 2000, 100),\n",
    "        'rf__max_depth': [3, 6, 9, 12],\n",
    "        'rf__max_features': [int(1), 'sqrt'],\n",
    "        'rf__min_weight_fraction_leaf': np.arange(0.0, 0.05, 0.005)}\n",
    "paramsRF = ParameterSampler(n_iter=N_ITER, param_distributions=grid)\n",
    "\n",
    "rfPipe = Pipeline(steps=[('scaler', RobustScaler()), ('rf',baseRF)])\n",
    "rfPipeFS = Pipeline(steps=[('scaler', RobustScaler()),\n",
    "                           ('selector', SelectFromModel(baseRF, threshold='mean')),\n",
    "                           ('rf',baseRF)])\n",
    "\n",
    "# Elastic Net Regressor\n",
    "net = ElasticNet(max_iter=1000)\n",
    "eNetPipe = Pipeline(steps=[('scaler', RobustScaler()), ('net', net)])\n",
    "eNetPipePCA = Pipeline(steps=[('scaler', RobustScaler()),\n",
    "                              ('pca', PCA(n_components=.95)),\n",
    "                              ('net', net)])\n",
    "\n",
    "eNet_grid = {'net__alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "             'net__l1_ratio': np.arange(0.10, .90, 0.01)}\n",
    "\n",
    "paramsNet = ParameterSampler(n_iter=N_ITER, param_distributions=eNet_grid)\n",
    "\n",
    "# MLP Regressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(16, 8),\n",
    "                   random_state=49,\n",
    "                   shuffle=False,\n",
    "                   max_iter=500,\n",
    "                   early_stopping=True,\n",
    "                   learning_rate='constant')\n",
    "\n",
    "mlp_pipe = Pipeline(steps=[('scaler', RobustScaler()), ('mlp', mlp)])\n",
    "mlp_pipeFS = Pipeline(steps=[('scaler', RobustScaler()),\n",
    "                             ('selector', SelectFromModel(baseRF, threshold='mean')),\n",
    "                             ('mlp', mlp)])\n",
    "mlp_grid = {'mlp__learning_rate_init': [.000001, .00001, .0001, .001],\n",
    "            'mlp__batch_size': [32, 64, 128, 256],\n",
    "            'mlp__hidden_layer_sizes': [(12, 6), (16, 8), (6, 3)],\n",
    "            'mlp__alpha': [.000001, .00001, .0001, .001, .01]}\n",
    "mlp_sampler = ParameterSampler(n_iter=N_ITER, param_distributions=mlp_grid)\n",
    "\n",
    "# append the models\n",
    "models = [(mlp_pipe, mlp_sampler, 'preds_MLP'),\n",
    "          (mlp_pipeFS, mlp_sampler, 'preds_MLP_FS'),\n",
    "          (eNetPipe, paramsNet, 'preds_eNet'),\n",
    "          (eNetPipePCA, paramsNet, 'preds_eNetPCA'),\n",
    "          (rfPipe, paramsRF, 'preds_RF'),\n",
    "          (rfPipeFS, paramsRF, 'preds_RF_FS')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Form the training loop, here we train on 3 year expanding windows, using 90% of each split for training and 10% for tuning hyper-parameters, we then use the same model to forecast forward 3-years before re-training again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(22698, 13) (2520, 13)\n",
      "Iter: 0: Score: 1.5695559441186155\n",
      "Iter: 1: Score: 1.5538991512473073\n",
      "Iter: 2: Score: 1.511695616963648\n",
      "Iter: 3: Score: 1.5714383746769396\n",
      "Iter: 4: Score: 1.5610912213320103\n",
      "Iter: 5: Score: 1.5714922585098985\n",
      "Iter: 6: Score: 1.585930052219177\n",
      "Iter: 7: Score: 1.5806578881545965\n",
      "Iter: 8: Score: 1.5840456658848232\n",
      "Iter: 9: Score: 1.5158070840786995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10: Score: 1.778308727766601\n",
      "Iter: 11: Score: 1.526327582432145\n",
      "Iter: 12: Score: 1.5540315299672618\n",
      "Iter: 13: Score: 1.5141805370656394\n",
      "Iter: 14: Score: 1.569658946990948\n",
      "Iter: 15: Score: 1.570819672843301\n",
      "Iter: 16: Score: 1.5506347313885065\n",
      "Iter: 17: Score: 1.520412822367633\n",
      "Iter: 18: Score: 1.5257591532803847\n",
      "Iter: 19: Score: 1.6176496555397364\n",
      "Iter: 20: Score: 1.6276754739863972\n",
      "Iter: 21: Score: 1.5829550920284765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 22: Score: 1.778306695564358\n",
      "Iter: 23: Score: 1.5363346208680706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 24: Score: 1.5882240195171047\n",
      "Iter: 25: Score: 1.584463489282359\n",
      "Iter: 26: Score: 1.5607619301826239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 27: Score: 1.996699522210766\n",
      "Iter: 28: Score: 1.5410065412343568\n",
      "Iter: 29: Score: 1.627713667953174\n",
      "Iter: 30: Score: 1.5684957883300807\n",
      "Iter: 31: Score: 1.5116955746657974\n",
      "Iter: 32: Score: 1.52260700995021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 33: Score: 1.778308623781538\n",
      "Iter: 34: Score: 1.6094944705458651\n",
      "Iter: 35: Score: 1.5185480181293116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 36: Score: 1.9967005776039495\n",
      "Iter: 37: Score: 1.5745358000315106\n",
      "Iter: 38: Score: 1.581170295475424\n",
      "Iter: 39: Score: 1.5430765685322982\n",
      "Iter: 40: Score: 1.514123410907738\n",
      "Iter: 41: Score: 1.5714915331342885\n",
      "Iter: 42: Score: 1.507608529838816\n",
      "Iter: 43: Score: 1.5144109172547615\n",
      "Iter: 44: Score: 1.5343369275448737\n",
      "Iter: 45: Score: 1.5949299893748823\n",
      "Iter: 46: Score: 1.5293589934834684\n",
      "Iter: 47: Score: 1.5916319657024738\n",
      "Iter: 48: Score: 1.6176393448718585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 49: Score: 1.5384330609974848\n",
      "      scores                                               grid\n",
      "42  1.507609  {'mlp__learning_rate_init': 1e-05, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 1e-05, 'mlp__hidden_layer_sizes': (6, 3), 'mlp__batch_size': 32, 'mlp__alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [05:39, 339.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45396, 13) (5040, 13)\n",
      "Iter: 0: Score: 1.510357970114223\n",
      "Iter: 1: Score: 1.7884133663059203\n",
      "Iter: 2: Score: 1.8105012903919853\n",
      "Iter: 3: Score: 1.7733566461931545\n",
      "Iter: 4: Score: 1.813450465492491\n",
      "Iter: 5: Score: 1.490001837202538\n",
      "Iter: 6: Score: 1.6672280607798693\n",
      "Iter: 7: Score: 1.5248242863563313\n",
      "Iter: 8: Score: 1.4568357049640912\n",
      "Iter: 9: Score: 1.4849808603808152\n",
      "Iter: 10: Score: 1.495292964438934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 11: Score: 1.6733762317148628\n",
      "Iter: 12: Score: 1.5114424674031004\n",
      "Iter: 13: Score: 1.6927925111710058\n",
      "Iter: 14: Score: 1.6421274685481555\n",
      "Iter: 15: Score: 1.7772589403741121\n",
      "Iter: 16: Score: 1.4809722061856507\n",
      "Iter: 17: Score: 1.5132688312163445\n",
      "Iter: 18: Score: 1.4726253834268075\n",
      "Iter: 19: Score: 1.474423962277312\n",
      "Iter: 20: Score: 1.4552569316630926\n",
      "Iter: 21: Score: 1.4974448435521481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 22: Score: 1.6733562920503569\n",
      "Iter: 23: Score: 2.703748639794367\n",
      "Iter: 24: Score: 1.689621293118061\n",
      "Iter: 25: Score: 1.8980260156971225\n",
      "Iter: 26: Score: 1.4879273663197214\n",
      "Iter: 27: Score: 1.76208276872405\n",
      "Iter: 28: Score: 2.882419149870423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 29: Score: 1.6733746081412586\n",
      "Iter: 30: Score: 1.4672166996862521\n",
      "Iter: 31: Score: 1.6957233132957414\n",
      "Iter: 32: Score: 1.4677069387621058\n",
      "Iter: 33: Score: 1.4942875589590445\n",
      "Iter: 34: Score: 1.693418982349866\n",
      "Iter: 35: Score: 1.4776846228920342\n",
      "Iter: 36: Score: 1.485408754849916\n",
      "Iter: 37: Score: 1.513138747073016\n",
      "Iter: 38: Score: 1.4943906172713939\n",
      "Iter: 39: Score: 1.472470764552852\n",
      "Iter: 40: Score: 1.773020474018636\n",
      "Iter: 41: Score: 1.4573336479972656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 42: Score: 2.0738323643189585\n",
      "Iter: 43: Score: 1.800442780337128\n",
      "Iter: 44: Score: 1.510356396541489\n",
      "Iter: 45: Score: 1.4675624659593085\n",
      "Iter: 46: Score: 1.7298719631551476\n",
      "Iter: 47: Score: 1.4580988766603769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 48: Score: 2.152169788566098\n",
      "Iter: 49: Score: 1.4613115329718196\n",
      "      scores                                               grid\n",
      "20  1.455257  {'mlp__learning_rate_init': 0.001, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 0.001, 'mlp__hidden_layer_sizes': (6, 3), 'mlp__batch_size': 256, 'mlp__alpha': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [13:04, 401.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68076, 13) (7560, 13)\n",
      "Iter: 0: Score: 1.3899506645001294\n",
      "Iter: 1: Score: 1.4082853916390061\n",
      "Iter: 2: Score: 1.3983778833803657\n",
      "Iter: 3: Score: 1.446018472705023\n",
      "Iter: 4: Score: 1.4025066237740234\n",
      "Iter: 5: Score: 1.4033776147186627\n",
      "Iter: 6: Score: 1.4199062008614873\n",
      "Iter: 7: Score: 1.3881069086389803\n",
      "Iter: 8: Score: 1.4083929761943152\n",
      "Iter: 9: Score: 1.4043365080631025\n",
      "Iter: 10: Score: 1.3873088680967045\n",
      "Iter: 11: Score: 1.3844887114877618\n",
      "Iter: 12: Score: 1.3965165078074466\n",
      "Iter: 13: Score: 1.383342938749077\n",
      "Iter: 14: Score: 1.3802220615025347\n",
      "Iter: 15: Score: 1.3843863876536324\n",
      "Iter: 16: Score: 1.4008695889078053\n",
      "Iter: 17: Score: 1.3802963615691695\n",
      "Iter: 18: Score: 1.411989155679296\n",
      "Iter: 19: Score: 1.384916548295015\n",
      "Iter: 20: Score: 1.39267270987991\n",
      "Iter: 21: Score: 1.3970605048011868\n",
      "Iter: 22: Score: 1.396496870430085\n",
      "Iter: 23: Score: 1.4110602493446864\n",
      "Iter: 24: Score: 1.3914313829301896\n",
      "Iter: 25: Score: 1.3845635342208364\n",
      "Iter: 26: Score: 1.4093910750821255\n",
      "Iter: 27: Score: 1.403377513702127\n",
      "Iter: 28: Score: 1.4395480713809419\n",
      "Iter: 29: Score: 1.383958317660699\n",
      "Iter: 30: Score: 1.3830964454062715\n",
      "Iter: 31: Score: 1.3842452502499647\n",
      "Iter: 32: Score: 1.4397629049443017\n",
      "Iter: 33: Score: 1.3961664381811671\n",
      "Iter: 34: Score: 1.439758073733549\n",
      "Iter: 35: Score: 1.3872499131257399\n",
      "Iter: 36: Score: 1.3852331977358971\n",
      "Iter: 37: Score: 1.3881008759371813\n",
      "Iter: 38: Score: 1.3864512639513984\n",
      "Iter: 39: Score: 1.4059753164434172\n",
      "Iter: 40: Score: 1.4256406611134553\n",
      "Iter: 41: Score: 1.3802956447461356\n",
      "Iter: 42: Score: 1.4460411844866554\n",
      "Iter: 43: Score: 1.390193069555017\n",
      "Iter: 44: Score: 1.389860587411814\n",
      "Iter: 45: Score: 1.3854817916243587\n",
      "Iter: 46: Score: 1.4033365707798968\n",
      "Iter: 47: Score: 1.3801437133950791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 48: Score: 1.596784760753772\n",
      "Iter: 49: Score: 1.3846464607483926\n",
      "      scores                                               grid\n",
      "47  1.380144  {'mlp__learning_rate_init': 1e-05, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 1e-05, 'mlp__hidden_layer_sizes': (12, 6), 'mlp__batch_size': 128, 'mlp__alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [22:58, 489.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90756, 13) (10080, 13)\n",
      "Iter: 0: Score: 1.5070261880644134\n",
      "Iter: 1: Score: 1.4837852278880261\n",
      "Iter: 2: Score: 1.5162753381087737\n",
      "Iter: 3: Score: 1.5100229929095665\n",
      "Iter: 4: Score: 1.5182536132625737\n",
      "Iter: 5: Score: 1.5099021659987015\n",
      "Iter: 6: Score: 1.506701409136582\n",
      "Iter: 7: Score: 1.531366047340112\n",
      "Iter: 8: Score: 1.5063348888991293\n",
      "Iter: 9: Score: 1.531402102293548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10: Score: 1.6109682005112682\n",
      "Iter: 11: Score: 1.5074244595340982\n",
      "Iter: 12: Score: 1.4922161413461728\n",
      "Iter: 13: Score: 1.507901446905601\n",
      "Iter: 14: Score: 1.5314058322789117\n",
      "Iter: 15: Score: 1.4962471705792155\n",
      "Iter: 16: Score: 1.4990791363482316\n",
      "Iter: 17: Score: 1.4842439207974996\n",
      "Iter: 18: Score: 1.5179675747736285\n",
      "Iter: 19: Score: 1.503364473105036\n",
      "Iter: 20: Score: 1.5209570243396526\n",
      "Iter: 21: Score: 1.5226756191894133\n",
      "Iter: 22: Score: 1.5135965584709214\n",
      "Iter: 23: Score: 1.5005720273277654\n",
      "Iter: 24: Score: 1.486273740376271\n",
      "Iter: 25: Score: 1.5019155636309391\n",
      "Iter: 26: Score: 1.4945696609398615\n",
      "Iter: 27: Score: 1.492681784333824\n",
      "Iter: 28: Score: 1.5067803794687917\n",
      "Iter: 29: Score: 1.494807687460788\n",
      "Iter: 30: Score: 1.4953553698533621\n",
      "Iter: 31: Score: 1.498331044001922\n",
      "Iter: 32: Score: 1.508827314266731\n",
      "Iter: 33: Score: 1.503580840705988\n",
      "Iter: 34: Score: 1.496238375711479\n",
      "Iter: 35: Score: 1.489607077530534\n",
      "Iter: 36: Score: 1.5018035937046545\n",
      "Iter: 37: Score: 1.4960320502210254\n",
      "Iter: 38: Score: 1.4949463801830465\n",
      "Iter: 39: Score: 1.4866040149726194\n",
      "Iter: 40: Score: 1.509900426119775\n",
      "Iter: 41: Score: 1.5226685655092405\n",
      "Iter: 42: Score: 1.5033588285987167\n",
      "Iter: 43: Score: 1.5182276112187532\n",
      "Iter: 44: Score: 1.5019227585702994\n",
      "Iter: 45: Score: 1.4944316661773183\n",
      "Iter: 46: Score: 1.4987814839273508\n",
      "Iter: 47: Score: 1.5276365298387415\n",
      "Iter: 48: Score: 1.5144127064939985\n",
      "Iter: 49: Score: 1.506885679487261\n",
      "     scores                                               grid\n",
      "1  1.483785  {'mlp__learning_rate_init': 0.001, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 0.001, 'mlp__hidden_layer_sizes': (6, 3), 'mlp__batch_size': 32, 'mlp__alpha': 1e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [33:00, 495.03s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(22698, 13) (2520, 13)\n",
      "Iter: 0: Score: 1.5343369275448737\n",
      "Iter: 1: Score: 1.5696580059218896\n",
      "Iter: 2: Score: 1.516485672244892\n",
      "Iter: 3: Score: 1.5346780112732306\n",
      "Iter: 4: Score: 1.546691448945916\n",
      "Iter: 5: Score: 1.5185480181293116\n",
      "Iter: 6: Score: 1.578813678031043\n",
      "Iter: 7: Score: 1.553195470388747\n",
      "Iter: 8: Score: 1.5135437189863141\n",
      "Iter: 9: Score: 1.6176393448718585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10: Score: 1.7783087476435455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 11: Score: 1.9967005776039495\n",
      "Iter: 12: Score: 1.5745358000315106\n",
      "Iter: 13: Score: 1.514004838923503\n",
      "Iter: 14: Score: 1.6405111689905332\n",
      "Iter: 15: Score: 1.5140908562486355\n",
      "Iter: 16: Score: 1.5185515920816934\n",
      "Iter: 17: Score: 1.5079384971798615\n",
      "Iter: 18: Score: 1.5293589934834684\n",
      "Iter: 19: Score: 1.580653257637794\n",
      "Iter: 20: Score: 1.5287417482522028\n",
      "Iter: 21: Score: 1.524709420831576\n",
      "Iter: 22: Score: 1.597271363502802\n",
      "Iter: 23: Score: 1.5317123387123754\n",
      "Iter: 24: Score: 1.585930052219177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 25: Score: 1.5882186569320145\n",
      "Iter: 26: Score: 1.5369124580687685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 27: Score: 1.778308727766601\n",
      "Iter: 28: Score: 1.5745497181452583\n",
      "Iter: 29: Score: 1.553211411013444\n",
      "Iter: 30: Score: 1.5144129568666578\n",
      "Iter: 31: Score: 1.5788148917624185\n",
      "Iter: 32: Score: 1.5141209142546526\n",
      "Iter: 33: Score: 1.525961175387534\n",
      "Iter: 34: Score: 1.5430765685322982\n",
      "Iter: 35: Score: 1.6405112940508497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 36: Score: 1.5882246378958116\n",
      "Iter: 37: Score: 1.574557756525366\n",
      "Iter: 38: Score: 1.528553942399463\n",
      "Iter: 39: Score: 1.5425903285459235\n",
      "Iter: 40: Score: 1.5840456658848232\n",
      "Iter: 41: Score: 1.507608529838816\n",
      "Iter: 42: Score: 1.5317328970320803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 43: Score: 1.5882246199281023\n",
      "Iter: 44: Score: 1.5760328000155073\n",
      "Iter: 45: Score: 1.5346903660001314\n",
      "Iter: 46: Score: 1.508011260393287\n",
      "Iter: 47: Score: 1.5369760082925163\n",
      "Iter: 48: Score: 1.578765212086901\n",
      "Iter: 49: Score: 1.5806575080941432\n",
      "      scores                                               grid\n",
      "41  1.507609  {'mlp__learning_rate_init': 1e-05, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 1e-05, 'mlp__hidden_layer_sizes': (6, 3), 'mlp__batch_size': 32, 'mlp__alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [06:23, 383.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45396, 13) (5040, 13)\n",
      "Iter: 0: Score: 1.472956252521877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1: Score: 1.6733562920503569\n",
      "Iter: 2: Score: 1.5350693295396507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3: Score: 2.073819755561519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4: Score: 2.0738323643189585\n",
      "Iter: 5: Score: 1.4686150926545392\n",
      "Iter: 6: Score: 1.5103516036070639\n",
      "Iter: 7: Score: 1.7730543404694077\n",
      "Iter: 8: Score: 2.504101553092651\n",
      "Iter: 9: Score: 1.4943907337873767\n",
      "Iter: 10: Score: 2.1491997745257034\n",
      "Iter: 11: Score: 1.6188985166914025\n",
      "Iter: 12: Score: 1.4854106393124773\n",
      "Iter: 13: Score: 1.898816016495261\n",
      "Iter: 14: Score: 1.4943906172713939\n",
      "Iter: 15: Score: 1.810303317809146\n",
      "Iter: 16: Score: 1.6927925111710058\n",
      "Iter: 17: Score: 1.8031979480628981\n",
      "Iter: 18: Score: 1.461747115566493\n",
      "Iter: 19: Score: 1.488879843512757\n",
      "Iter: 20: Score: 1.4552570471528183\n",
      "Iter: 21: Score: 1.9215484800509526\n",
      "Iter: 22: Score: 1.4852340319068693\n",
      "Iter: 23: Score: 1.5257576485458748\n",
      "Iter: 24: Score: 1.8105012903919853\n",
      "Iter: 25: Score: 1.7298719631551476\n",
      "Iter: 26: Score: 2.2993724422721273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 27: Score: 2.1521856467534226\n",
      "Iter: 28: Score: 1.4809722061856507\n",
      "Iter: 29: Score: 1.5350694984022253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 30: Score: 2.1521838377503766\n",
      "Iter: 31: Score: 1.5131892972043097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 32: Score: 1.6733746081412586\n",
      "Iter: 33: Score: 1.4943902542855807\n",
      "Iter: 34: Score: 1.7980995322271227\n",
      "Iter: 35: Score: 1.5114853751894353\n",
      "Iter: 36: Score: 1.8966419991057513\n",
      "Iter: 37: Score: 1.513184721473235\n",
      "Iter: 38: Score: 1.4900508612441958\n",
      "Iter: 39: Score: 1.4579561963529155\n",
      "Iter: 40: Score: 1.4764603479874063\n",
      "Iter: 41: Score: 1.5350513843476248\n",
      "Iter: 42: Score: 1.6957233132957414\n",
      "Iter: 43: Score: 1.485442105283069\n",
      "Iter: 44: Score: 1.4864857033167995\n",
      "Iter: 45: Score: 1.4729740174790393\n",
      "Iter: 46: Score: 1.8201098848627169\n",
      "Iter: 47: Score: 1.4563272219230186\n",
      "Iter: 48: Score: 1.8023717839876146\n",
      "Iter: 49: Score: 1.8100308621570194\n",
      "      scores                                               grid\n",
      "20  1.455257  {'mlp__learning_rate_init': 0.001, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 0.001, 'mlp__hidden_layer_sizes': (6, 3), 'mlp__batch_size': 256, 'mlp__alpha': 1e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [14:00, 426.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68076, 13) (7560, 13)\n",
      "Iter: 0: Score: 1.400149753705966\n",
      "Iter: 1: Score: 1.393392255864178\n",
      "Iter: 2: Score: 1.4141301785603457\n",
      "Iter: 3: Score: 1.3852331977358971\n",
      "Iter: 4: Score: 1.3802963615691695\n",
      "Iter: 5: Score: 1.4084254902560283\n",
      "Iter: 6: Score: 1.3910311324356648\n",
      "Iter: 7: Score: 1.4110602493446864\n",
      "Iter: 8: Score: 1.3873878288479689\n",
      "Iter: 9: Score: 1.3802242927967598\n",
      "Iter: 10: Score: 1.3899471328571067\n",
      "Iter: 11: Score: 1.396496870430085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 12: Score: 1.596784760753772\n",
      "Iter: 13: Score: 1.4460368219661501\n",
      "Iter: 14: Score: 1.3881069468158216\n",
      "Iter: 15: Score: 1.4063050878628416\n",
      "Iter: 16: Score: 1.388041708865007\n",
      "Iter: 17: Score: 1.3885940305487054\n",
      "Iter: 18: Score: 1.4008521620673757\n",
      "Iter: 19: Score: 1.3845929915349453\n",
      "Iter: 20: Score: 1.3843863876536324\n",
      "Iter: 21: Score: 1.3872499131257399\n",
      "Iter: 22: Score: 1.393399426133024\n",
      "Iter: 23: Score: 1.4007069038009956\n",
      "Iter: 24: Score: 1.408430232889951\n",
      "Iter: 25: Score: 1.3986357243020127\n",
      "Iter: 26: Score: 1.403377513702127\n",
      "Iter: 27: Score: 1.4397624051215043\n",
      "Iter: 28: Score: 1.4085813266950757\n",
      "Iter: 29: Score: 1.3830964454062715\n",
      "Iter: 30: Score: 1.3803826639954158\n",
      "Iter: 31: Score: 1.3899326755155863\n",
      "Iter: 32: Score: 1.4024288760918098\n",
      "Iter: 33: Score: 1.4009286868377375\n",
      "Iter: 34: Score: 1.402089114075139\n",
      "Iter: 35: Score: 1.3803840759420938\n",
      "Iter: 36: Score: 1.408562965654131\n",
      "Iter: 37: Score: 1.4043496349721503\n",
      "Iter: 38: Score: 1.3996263786290852\n",
      "Iter: 39: Score: 1.3843345093837482\n",
      "Iter: 40: Score: 1.38816344149651\n",
      "Iter: 41: Score: 1.4044664736729395\n",
      "Iter: 42: Score: 1.3802957310806248\n",
      "Iter: 43: Score: 1.401957624680331\n",
      "Iter: 44: Score: 1.3881751314423232\n",
      "Iter: 45: Score: 1.3899438591373194\n",
      "Iter: 46: Score: 1.3845854867673322\n",
      "Iter: 47: Score: 1.3844067758786205\n",
      "Iter: 48: Score: 1.3845960020915495\n",
      "Iter: 49: Score: 1.3864022517692423\n",
      "     scores                                               grid\n",
      "9  1.380224  {'mlp__learning_rate_init': 1e-05, 'mlp__hidde...\n",
      "Best Model: {'mlp__learning_rate_init': 1e-05, 'mlp__hidden_layer_sizes': (12, 6), 'mlp__batch_size': 128, 'mlp__alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [30:17, 677.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90756, 13) (10080, 13)\n",
      "Iter: 0: Score: 1.5225577802585057\n",
      "Iter: 1: Score: 1.5054585621440308\n",
      "Iter: 2: Score: 1.518256860041431\n",
      "Iter: 3: Score: 1.5069427866936167\n",
      "Iter: 4: Score: 1.4983307994044415\n",
      "Iter: 5: Score: 1.4987814839273508\n",
      "Iter: 6: Score: 1.5019227585702994\n",
      "Iter: 7: Score: 1.5035985872229904\n",
      "Iter: 8: Score: 1.4954186639893452\n",
      "Iter: 9: Score: 1.5276365298387415\n",
      "Iter: 10: Score: 1.488961845021126\n",
      "Iter: 11: Score: 1.506290456276585\n",
      "Iter: 12: Score: 1.5067625058967644\n",
      "Iter: 13: Score: 1.5072758172316225\n",
      "Iter: 14: Score: 1.5022826955929844\n",
      "Iter: 15: Score: 1.520871328793544\n",
      "Iter: 16: Score: 1.5079070272863697\n",
      "Iter: 17: Score: 1.5107356390471451\n",
      "Iter: 18: Score: 1.5314058521380767\n",
      "Iter: 19: Score: 1.4872979581293213\n",
      "Iter: 20: Score: 1.5209579127033173\n",
      "Iter: 21: Score: 1.4983340576024657\n",
      "Iter: 22: Score: 1.5033588285987167\n",
      "Iter: 23: Score: 1.5226685655092405\n",
      "Iter: 24: Score: 1.496217043420794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 25: Score: 1.6109682005112682\n",
      "Iter: 26: Score: 1.503580840705988\n",
      "Iter: 27: Score: 1.4872091972832053\n",
      "Iter: 28: Score: 1.5081566417111774\n",
      "Iter: 29: Score: 1.5026740337860818\n",
      "Iter: 30: Score: 1.5029365972386803\n",
      "Iter: 31: Score: 1.5049421077830838\n",
      "Iter: 32: Score: 1.4986543479248249\n",
      "Iter: 33: Score: 1.506885679487261\n",
      "Iter: 34: Score: 1.4866479901672327\n",
      "Iter: 35: Score: 1.4988127767691857\n",
      "Iter: 36: Score: 1.4871058021776147\n",
      "Iter: 37: Score: 1.5008068056074126\n",
      "Iter: 38: Score: 1.4889494918219217\n",
      "Iter: 39: Score: 1.5352172690611745\n",
      "Iter: 40: Score: 1.5049538300670562\n",
      "Iter: 41: Score: 1.4893838012253215\n",
      "Iter: 42: Score: 1.4892189966309224\n",
      "Iter: 43: Score: 1.4867155183212197\n",
      "Iter: 44: Score: 1.503938617641269\n",
      "Iter: 45: Score: 1.4962471705792155\n",
      "Iter: 46: Score: 1.5127309290771658\n",
      "Iter: 47: Score: 1.5179675747736285\n",
      "Iter: 48: Score: 1.4963837314425024\n",
      "Iter: 49: Score: 1.4921029870292077\n",
      "      scores                                               grid\n",
      "34  1.486648  {'mlp__learning_rate_init': 0.0001, 'mlp__hidd...\n",
      "Best Model: {'mlp__learning_rate_init': 0.0001, 'mlp__hidden_layer_sizes': (6, 3), 'mlp__batch_size': 32, 'mlp__alpha': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [41:13, 618.34s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(22698, 13) (2520, 13)\n",
      "Iter: 0: Score: 1.5045307470349951\n",
      "Iter: 1: Score: 1.5051193698271668\n",
      "Iter: 2: Score: 1.5021570968784421\n",
      "Iter: 3: Score: 1.5051243208085903\n",
      "Iter: 4: Score: 1.5051204180713855\n",
      "Iter: 5: Score: 1.5051008515128061\n",
      "Iter: 6: Score: 1.5011795887475294\n",
      "Iter: 7: Score: 1.5050904553947604\n",
      "Iter: 8: Score: 1.5051211780833404\n",
      "Iter: 9: Score: 1.5043791968957907\n",
      "Iter: 10: Score: 1.5019506810650698\n",
      "Iter: 11: Score: 1.5048950356735933\n",
      "Iter: 12: Score: 1.505122890940164\n",
      "Iter: 13: Score: 1.5017915557537773\n",
      "Iter: 14: Score: 1.5051217505030727\n",
      "Iter: 15: Score: 1.5051234633545894\n",
      "Iter: 16: Score: 1.5050564109148492\n",
      "Iter: 17: Score: 1.5051237486957914\n",
      "Iter: 18: Score: 1.505030788398937\n",
      "Iter: 19: Score: 1.5051256555251182\n",
      "Iter: 20: Score: 1.5050989589131503\n",
      "Iter: 21: Score: 1.50438899610845\n",
      "Iter: 22: Score: 1.500423724517486\n",
      "Iter: 23: Score: 1.5051196543889922\n",
      "Iter: 24: Score: 1.5046809922159718\n",
      "Iter: 25: Score: 1.5050488085871505\n",
      "Iter: 26: Score: 1.5047331114809541\n",
      "Iter: 27: Score: 1.504219497465067\n",
      "Iter: 28: Score: 1.504840139307951\n",
      "Iter: 29: Score: 1.5003803071293247\n",
      "Iter: 30: Score: 1.5049043092567898\n",
      "Iter: 31: Score: 1.5008809462722303\n",
      "Iter: 32: Score: 1.5002303357091056\n",
      "Iter: 33: Score: 1.505125846178967\n",
      "Iter: 34: Score: 1.5050507074940738\n",
      "Iter: 35: Score: 1.5046553370370963\n",
      "Iter: 36: Score: 1.505079129459953\n",
      "Iter: 37: Score: 1.5010603526577146\n",
      "Iter: 38: Score: 1.5044986650860748\n",
      "Iter: 39: Score: 1.5051212749743392\n",
      "Iter: 40: Score: 1.5012565599178092\n",
      "Iter: 41: Score: 1.5050923407329349\n",
      "Iter: 42: Score: 1.5013945181480344\n",
      "Iter: 43: Score: 1.5051188919089575\n",
      "Iter: 44: Score: 1.5046468406041642\n",
      "Iter: 45: Score: 1.503121097363874\n",
      "Iter: 46: Score: 1.5051247025017374\n",
      "Iter: 47: Score: 1.5050951768218264\n",
      "Iter: 48: Score: 1.500780355725714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 49: Score: 1.505122416854154\n",
      "     scores                                               grid\n",
      "32  1.50023  {'net__l1_ratio': 0.8599999999999995, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.8599999999999995, 'net__alpha': 0.01}\n",
      "(45396, 13) (5040, 13)\n",
      "Iter: 0: Score: 1.4417633849262483\n",
      "Iter: 1: Score: 1.4444566607144562\n",
      "Iter: 2: Score: 1.4416637860374306\n",
      "Iter: 3: Score: 1.4416395072818395\n",
      "Iter: 4: Score: 1.4416513640572777\n",
      "Iter: 5: Score: 1.4417933531387637\n",
      "Iter: 6: Score: 1.4416308564705589\n",
      "Iter: 7: Score: 1.4417925984781017\n",
      "Iter: 8: Score: 1.4426670917475886\n",
      "Iter: 9: Score: 1.4444375700412784\n",
      "Iter: 10: Score: 1.4420196826284206\n",
      "Iter: 11: Score: 1.4417652634942209\n",
      "Iter: 12: Score: 1.4417607769137264\n",
      "Iter: 13: Score: 1.4417586756738172\n",
      "Iter: 14: Score: 1.44302712417052\n",
      "Iter: 15: Score: 1.4416348416877587\n",
      "Iter: 16: Score: 1.4417581953445913\n",
      "Iter: 17: Score: 1.4417721198746518\n",
      "Iter: 18: Score: 1.441759455718743\n",
      "Iter: 19: Score: 1.4417942328474416\n",
      "Iter: 20: Score: 1.4416421646706372\n",
      "Iter: 21: Score: 1.4438873728287789\n",
      "Iter: 22: Score: 1.441637433847506\n",
      "Iter: 23: Score: 1.444522018936175\n",
      "Iter: 24: Score: 1.4444981537687223\n",
      "Iter: 25: Score: 1.4417738040532229\n",
      "Iter: 26: Score: 1.4417685291954303\n",
      "Iter: 27: Score: 1.4417690748362617\n",
      "Iter: 28: Score: 1.4417943232438328\n",
      "Iter: 29: Score: 1.4444665624372235\n",
      "Iter: 30: Score: 1.4417740871129212\n",
      "Iter: 31: Score: 1.4417754987007783\n",
      "Iter: 32: Score: 1.4417631364004775\n",
      "Iter: 33: Score: 1.4416563935113889\n",
      "Iter: 34: Score: 1.441774934691928\n",
      "Iter: 35: Score: 1.4417922975367699\n",
      "Iter: 36: Score: 1.4417628883106963\n",
      "Iter: 37: Score: 1.4417935053578965\n",
      "Iter: 38: Score: 1.441758972658866\n",
      "Iter: 39: Score: 1.441634143691466\n",
      "Iter: 40: Score: 1.4442276324802052\n",
      "Iter: 41: Score: 1.4444313345599036\n",
      "Iter: 42: Score: 1.441792507850976\n",
      "Iter: 43: Score: 1.4444873353533885\n",
      "Iter: 44: Score: 1.4416480603477029\n",
      "Iter: 45: Score: 1.4416622213664134\n",
      "Iter: 46: Score: 1.4417939296773734\n",
      "Iter: 47: Score: 1.4416670493032528\n",
      "Iter: 48: Score: 1.4417729528274887\n",
      "Iter: 49: Score: 1.442096401126552\n",
      "     scores                                               grid\n",
      "6  1.441631  {'net__l1_ratio': 0.30999999999999994, 'net__a...\n",
      "Best Model: {'net__l1_ratio': 0.30999999999999994, 'net__alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:16,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68076, 13) (7560, 13)\n",
      "Iter: 0: Score: 1.3829304358300978\n",
      "Iter: 1: Score: 1.3839909675871516\n",
      "Iter: 2: Score: 1.383985416171783\n",
      "Iter: 3: Score: 1.3834818782401257\n",
      "Iter: 4: Score: 1.384197813341672\n",
      "Iter: 5: Score: 1.3842238674615417\n",
      "Iter: 6: Score: 1.3842025833584843\n",
      "Iter: 7: Score: 1.3837734478379966\n",
      "Iter: 8: Score: 1.3842388434577968\n",
      "Iter: 9: Score: 1.3837654215408577\n",
      "Iter: 10: Score: 1.3842245591173985\n",
      "Iter: 11: Score: 1.3841876595951121\n",
      "Iter: 12: Score: 1.3842412260505244\n",
      "Iter: 13: Score: 1.3841937399731852\n",
      "Iter: 14: Score: 1.381386067231184\n",
      "Iter: 15: Score: 1.3842397537126243\n",
      "Iter: 16: Score: 1.3841910334439427\n",
      "Iter: 17: Score: 1.3842391936958356\n",
      "Iter: 18: Score: 1.3842386334727348\n",
      "Iter: 19: Score: 1.3842405246705842\n",
      "Iter: 20: Score: 1.3841024415778338\n",
      "Iter: 21: Score: 1.3841795829064498\n",
      "Iter: 22: Score: 1.384194425734931\n",
      "Iter: 23: Score: 1.3841930658422366\n",
      "Iter: 24: Score: 1.3842414364692108\n",
      "Iter: 25: Score: 1.3841998534231983\n",
      "Iter: 26: Score: 1.3819625314308213\n",
      "Iter: 27: Score: 1.3838809662525662\n",
      "Iter: 28: Score: 1.3842224844672095\n",
      "Iter: 29: Score: 1.3842380033638821\n",
      "Iter: 30: Score: 1.3816802031268554\n",
      "Iter: 31: Score: 1.3827710045355945\n",
      "Iter: 32: Score: 1.3837536682224367\n",
      "Iter: 33: Score: 1.3842128466226942\n",
      "Iter: 34: Score: 1.3842407350014405\n",
      "Iter: 35: Score: 1.384216283129721\n",
      "Iter: 36: Score: 1.3841815878093084\n",
      "Iter: 37: Score: 1.3842420680690841\n",
      "Iter: 38: Score: 1.3842149091674512\n",
      "Iter: 39: Score: 1.3839421025473633\n",
      "Iter: 40: Score: 1.3827506273408776\n",
      "Iter: 41: Score: 1.384237862877552\n",
      "Iter: 42: Score: 1.384237793267769\n",
      "Iter: 43: Score: 1.3824340438980818\n",
      "Iter: 44: Score: 1.3842394036137589\n",
      "Iter: 45: Score: 1.384240665269341\n",
      "Iter: 46: Score: 1.3834589602291532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:26,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 47: Score: 1.3842314899745956\n",
      "Iter: 48: Score: 1.3817107551322436\n",
      "Iter: 49: Score: 1.3826660312442818\n",
      "      scores                                               grid\n",
      "14  1.381386  {'net__l1_ratio': 0.7299999999999996, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.7299999999999996, 'net__alpha': 0.01}\n",
      "(90756, 13) (10080, 13)\n",
      "Iter: 0: Score: 1.4858577695495454\n",
      "Iter: 1: Score: 1.4867150204238488\n",
      "Iter: 2: Score: 1.4845940685839174\n",
      "Iter: 3: Score: 1.4868164414508935\n",
      "Iter: 4: Score: 1.4849549785497211\n",
      "Iter: 5: Score: 1.4868143929142672\n",
      "Iter: 6: Score: 1.4868016533780226\n",
      "Iter: 7: Score: 1.4859239397819433\n",
      "Iter: 8: Score: 1.4868077934547168\n",
      "Iter: 9: Score: 1.4866369843377965\n",
      "Iter: 10: Score: 1.4848497759797816\n",
      "Iter: 11: Score: 1.4866214684913754\n",
      "Iter: 12: Score: 1.4852872656323115\n",
      "Iter: 13: Score: 1.4846829500204108\n",
      "Iter: 14: Score: 1.486089344123505\n",
      "Iter: 15: Score: 1.4868082493990105\n",
      "Iter: 16: Score: 1.4868109791268667\n",
      "Iter: 17: Score: 1.4866703655043718\n",
      "Iter: 18: Score: 1.485808215110898\n",
      "Iter: 19: Score: 1.4867105519078496\n",
      "Iter: 20: Score: 1.4866103678327052\n",
      "Iter: 21: Score: 1.4858949363712222\n",
      "Iter: 22: Score: 1.4866081151366168\n",
      "Iter: 23: Score: 1.4867329233429285\n",
      "Iter: 24: Score: 1.4845602475195916\n",
      "Iter: 25: Score: 1.48680916081704\n",
      "Iter: 26: Score: 1.4858125376245148\n",
      "Iter: 27: Score: 1.4868062029313973\n",
      "Iter: 28: Score: 1.4868055204592545\n",
      "Iter: 29: Score: 1.486739640766169\n",
      "Iter: 30: Score: 1.486688186640612\n",
      "Iter: 31: Score: 1.486683755430961\n",
      "Iter: 32: Score: 1.4861250728141708\n",
      "Iter: 33: Score: 1.4859659931777887\n",
      "Iter: 34: Score: 1.4866391889197024\n",
      "Iter: 35: Score: 1.4868130274558793\n",
      "Iter: 36: Score: 1.4867239597684014\n",
      "Iter: 37: Score: 1.4867284306664057\n",
      "Iter: 38: Score: 1.4858672878339902\n",
      "Iter: 39: Score: 1.486805976898868\n",
      "Iter: 40: Score: 1.4868146209658433\n",
      "Iter: 41: Score: 1.485422953866078\n",
      "Iter: 42: Score: 1.486803703000922\n",
      "Iter: 43: Score: 1.4868132558741767\n",
      "Iter: 44: Score: 1.4849196439596921\n",
      "Iter: 45: Score: 1.486775547924652\n",
      "Iter: 46: Score: 1.4860228734781247\n",
      "Iter: 47: Score: 1.486753093360393\n",
      "Iter: 48: Score: 1.4859122255554595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:37,  9.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 49: Score: 1.4867038362768417\n",
      "     scores                                               grid\n",
      "24  1.48456  {'net__l1_ratio': 0.5299999999999998, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.5299999999999998, 'net__alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(22698, 13) (2520, 13)\n",
      "Iter: 0: Score: 1.5016574642637024\n",
      "Iter: 1: Score: 1.5011826749440342\n",
      "Iter: 2: Score: 1.5016978301365107\n",
      "Iter: 3: Score: 1.4996151147636048\n",
      "Iter: 4: Score: 1.5016701526735905\n",
      "Iter: 5: Score: 1.5015583850217156\n",
      "Iter: 6: Score: 1.4990790757667063\n",
      "Iter: 7: Score: 1.5009608780412778\n",
      "Iter: 8: Score: 1.4982107004025027\n",
      "Iter: 9: Score: 1.501667131066111\n",
      "Iter: 10: Score: 1.500560186552734\n",
      "Iter: 11: Score: 1.5016520282555736\n",
      "Iter: 12: Score: 1.5014205781588144\n",
      "Iter: 13: Score: 1.5015283643036004\n",
      "Iter: 14: Score: 1.501697104031527\n",
      "Iter: 15: Score: 1.501697588099287\n",
      "Iter: 16: Score: 1.4988857072569184\n",
      "Iter: 17: Score: 1.50160047246234\n",
      "Iter: 18: Score: 1.5009032287546828\n",
      "Iter: 19: Score: 1.5016997665145482\n",
      "Iter: 20: Score: 1.5016992824066644\n",
      "Iter: 21: Score: 1.501588440526248\n",
      "Iter: 22: Score: 1.5016980721759634\n",
      "Iter: 23: Score: 1.5016604847561381\n",
      "Iter: 24: Score: 1.501699040356066\n",
      "Iter: 25: Score: 1.5014504734267378\n",
      "Iter: 26: Score: 1.5013847499185031\n",
      "Iter: 27: Score: 1.5016586724188574\n",
      "Iter: 28: Score: 1.4978127337109748\n",
      "Iter: 29: Score: 1.5016987983076968\n",
      "Iter: 30: Score: 1.5011530948075715\n",
      "Iter: 31: Score: 1.5001661960284671\n",
      "Iter: 32: Score: 1.501468427332408\n",
      "Iter: 33: Score: 1.4996695952536125\n",
      "Iter: 34: Score: 1.5016999480573032\n",
      "Iter: 35: Score: 1.501681033345042\n",
      "Iter: 36: Score: 1.501693128274094\n",
      "Iter: 37: Score: 1.501194516834049\n",
      "Iter: 38: Score: 1.5016478010300058\n",
      "Iter: 39: Score: 1.501697285555892\n",
      "Iter: 40: Score: 1.501653840132811\n",
      "Iter: 41: Score: 1.5012953995407006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 42: Score: 1.5016964384529166\n",
      "Iter: 43: Score: 1.501698677284348\n",
      "Iter: 44: Score: 1.5015764141517565\n",
      "Iter: 45: Score: 1.5016749879702098\n",
      "Iter: 46: Score: 1.501670757036895\n",
      "Iter: 47: Score: 1.5016993429196621\n",
      "Iter: 48: Score: 1.5014564566669755\n",
      "Iter: 49: Score: 1.5016957123863872\n",
      "      scores                                               grid\n",
      "28  1.497813  {'net__l1_ratio': 0.7999999999999996, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.7999999999999996, 'net__alpha': 0.01}\n",
      "(45396, 13) (5040, 13)\n",
      "Iter: 0: Score: 1.448915816301441\n",
      "Iter: 1: Score: 1.4512010265745252\n",
      "Iter: 2: Score: 1.4413556556559726\n",
      "Iter: 3: Score: 1.4512016625356063\n",
      "Iter: 4: Score: 1.4511921248032373\n",
      "Iter: 5: Score: 1.451111166943923\n",
      "Iter: 6: Score: 1.451199436741982\n",
      "Iter: 7: Score: 1.4511898998515431\n",
      "Iter: 8: Score: 1.4507433321887961\n",
      "Iter: 9: Score: 1.4413340470060432\n",
      "Iter: 10: Score: 1.4511943499513837\n",
      "Iter: 11: Score: 1.451168257870158\n",
      "Iter: 12: Score: 1.4427072037904887\n",
      "Iter: 13: Score: 1.441670555079876\n",
      "Iter: 14: Score: 1.4443816645170333\n",
      "Iter: 15: Score: 1.4441709263362414\n",
      "Iter: 16: Score: 1.4503720277479837\n",
      "Iter: 17: Score: 1.4510605285005111\n",
      "Iter: 18: Score: 1.451006837624996\n",
      "Iter: 19: Score: 1.4489445705551278\n",
      "Iter: 20: Score: 1.4511864038957976\n",
      "Iter: 21: Score: 1.4509343815019047\n",
      "Iter: 22: Score: 1.4509564109057378\n",
      "Iter: 23: Score: 1.4413153710183717\n",
      "Iter: 24: Score: 1.4512029345058781\n",
      "Iter: 25: Score: 1.445037772269482\n",
      "Iter: 26: Score: 1.4510858348922586\n",
      "Iter: 27: Score: 1.4511587336961849\n",
      "Iter: 28: Score: 1.4415165550012272\n",
      "Iter: 29: Score: 1.4511848149853754\n",
      "Iter: 30: Score: 1.4510352477704338\n",
      "Iter: 31: Score: 1.451047884927654\n",
      "Iter: 32: Score: 1.450975308893914\n",
      "Iter: 33: Score: 1.4511492131299288\n",
      "Iter: 34: Score: 1.4485739048281538\n",
      "Iter: 35: Score: 1.4413615140780642\n",
      "Iter: 36: Score: 1.4511777856517558\n",
      "Iter: 37: Score: 1.4413243413759707\n",
      "Iter: 38: Score: 1.441329102413933\n",
      "Iter: 39: Score: 1.449557698852115\n",
      "Iter: 40: Score: 1.441488739296449\n",
      "Iter: 41: Score: 1.4487156633907132\n",
      "Iter: 42: Score: 1.4510226170290697\n",
      "Iter: 43: Score: 1.4511841794492717\n",
      "Iter: 44: Score: 1.4512070688522676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 45: Score: 1.4497062935525513\n",
      "Iter: 46: Score: 1.4503107045015022\n",
      "Iter: 47: Score: 1.451063690396143\n",
      "Iter: 48: Score: 1.4511016644176387\n",
      "Iter: 49: Score: 1.4511968932183892\n",
      "      scores                                               grid\n",
      "23  1.441315  {'net__l1_ratio': 0.8799999999999996, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.8799999999999996, 'net__alpha': 0.01}\n",
      "(68076, 13) (7560, 13)\n",
      "Iter: 0: Score: 1.3812751539241495\n",
      "Iter: 1: Score: 1.3811162739370637\n",
      "Iter: 2: Score: 1.3819026658186886\n",
      "Iter: 3: Score: 1.3819024554706736\n",
      "Iter: 4: Score: 1.3812847097352754\n",
      "Iter: 5: Score: 1.3818630611885991\n",
      "Iter: 6: Score: 1.381876771818111\n",
      "Iter: 7: Score: 1.3811715779239926\n",
      "Iter: 8: Score: 1.3818978060062286\n",
      "Iter: 9: Score: 1.3819027639911832\n",
      "Iter: 10: Score: 1.3818461073450374\n",
      "Iter: 11: Score: 1.3810528204016992\n",
      "Iter: 12: Score: 1.3818989246924565\n",
      "Iter: 13: Score: 1.381898714874911\n",
      "Iter: 14: Score: 1.3818994143813796\n",
      "Iter: 15: Score: 1.3818447598967953\n",
      "Iter: 16: Score: 1.3818521871077956\n",
      "Iter: 17: Score: 1.3819023993828479\n",
      "Iter: 18: Score: 1.3819010244893317\n",
      "Iter: 19: Score: 1.3810438497042716\n",
      "Iter: 20: Score: 1.3818488061801475\n",
      "Iter: 21: Score: 1.3819001842168286\n",
      "Iter: 22: Score: 1.381896688158642\n",
      "Iter: 23: Score: 1.3819027710037501\n",
      "Iter: 24: Score: 1.3818712718354835\n",
      "Iter: 25: Score: 1.3819025746642626\n",
      "Iter: 26: Score: 1.3812089152572544\n",
      "Iter: 27: Score: 1.3819024134046076\n",
      "Iter: 28: Score: 1.3818692147487714\n",
      "Iter: 29: Score: 1.3818991345394838\n",
      "Iter: 30: Score: 1.381902728928841\n",
      "Iter: 31: Score: 1.3810889385440148\n",
      "Iter: 32: Score: 1.3818774607902606\n",
      "Iter: 33: Score: 1.3819016550032257\n",
      "Iter: 34: Score: 1.3811808771981566\n",
      "Iter: 35: Score: 1.3815412875256279\n",
      "Iter: 36: Score: 1.381902806067075\n",
      "Iter: 37: Score: 1.3819026798429375\n",
      "Iter: 38: Score: 1.381902525583403\n",
      "Iter: 39: Score: 1.381802628274021\n",
      "Iter: 40: Score: 1.3819006042941235\n",
      "Iter: 41: Score: 1.3818474561061924\n",
      "Iter: 42: Score: 1.3818992744538805\n",
      "Iter: 43: Score: 1.3818719581864867\n",
      "Iter: 44: Score: 1.381886447232859\n",
      "Iter: 45: Score: 1.3813717569079313\n",
      "Iter: 46: Score: 1.3811995458766286\n",
      "Iter: 47: Score: 1.3819009544486087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 48: Score: 1.3819024484595808\n",
      "Iter: 49: Score: 1.3819026027111885\n",
      "      scores                                               grid\n",
      "19  1.381044  {'net__l1_ratio': 0.8899999999999996, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.8899999999999996, 'net__alpha': 0.01}\n",
      "(90756, 13) (10080, 13)\n",
      "Iter: 0: Score: 1.4854448534606746\n",
      "Iter: 1: Score: 1.4854363353255278\n",
      "Iter: 2: Score: 1.4853694375415787\n",
      "Iter: 3: Score: 1.484576666796441\n",
      "Iter: 4: Score: 1.4854449558155307\n",
      "Iter: 5: Score: 1.4846943207642145\n",
      "Iter: 6: Score: 1.4851418273319112\n",
      "Iter: 7: Score: 1.4854208584499697\n",
      "Iter: 8: Score: 1.4854365903853097\n",
      "Iter: 9: Score: 1.4848634226821655\n",
      "Iter: 10: Score: 1.4846778220798857\n",
      "Iter: 11: Score: 1.4854448406665905\n",
      "Iter: 12: Score: 1.485444712729092\n",
      "Iter: 13: Score: 1.4849919234402853\n",
      "Iter: 14: Score: 1.4853681961341225\n",
      "Iter: 15: Score: 1.4854453268844559\n",
      "Iter: 16: Score: 1.4854453012918563\n",
      "Iter: 17: Score: 1.484736655268726\n",
      "Iter: 18: Score: 1.4849018590798566\n",
      "Iter: 19: Score: 1.4854418244634429\n",
      "Iter: 20: Score: 1.485333683805424\n",
      "Iter: 21: Score: 1.485445122150459\n",
      "Iter: 22: Score: 1.48544489184329\n",
      "Iter: 23: Score: 1.4850126092511393\n",
      "Iter: 24: Score: 1.484645572356852\n",
      "Iter: 25: Score: 1.4853818850598943\n",
      "Iter: 26: Score: 1.4854157968447324\n",
      "Iter: 27: Score: 1.48456932405243\n",
      "Iter: 28: Score: 1.4848825181205292\n",
      "Iter: 29: Score: 1.4853558155182147\n",
      "Iter: 30: Score: 1.4853545808033413\n",
      "Iter: 31: Score: 1.4854340408806237\n",
      "Iter: 32: Score: 1.4854396529972718\n",
      "Iter: 33: Score: 1.4853756537008513\n",
      "Iter: 34: Score: 1.4854120070115873\n",
      "Iter: 35: Score: 1.4854449814048518\n",
      "Iter: 36: Score: 1.48506538850756\n",
      "Iter: 37: Score: 1.4854419522513884\n",
      "Iter: 38: Score: 1.4854448022847035\n",
      "Iter: 39: Score: 1.4852561583498953\n",
      "Iter: 40: Score: 1.4854453140881256\n",
      "Iter: 41: Score: 1.485439269979506\n",
      "Iter: 42: Score: 1.485350880310771\n",
      "Iter: 43: Score: 1.4854449686101607\n",
      "Iter: 44: Score: 1.485337358720898\n",
      "Iter: 45: Score: 1.4854341682981629\n",
      "Iter: 46: Score: 1.4854082226402716\n",
      "Iter: 47: Score: 1.4854378660485714\n",
      "Iter: 48: Score: 1.4853881316138724\n",
      "Iter: 49: Score: 1.4848445730743953\n",
      "      scores                                               grid\n",
      "27  1.484569  {'net__l1_ratio': 0.8499999999999996, 'net__al...\n",
      "Best Model: {'net__l1_ratio': 0.8499999999999996, 'net__alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.73s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(22698, 13) (2520, 13)\n",
      "Iter: 0: Score: 1.498592133975579\n",
      "Iter: 1: Score: 1.5087908498438007\n",
      "Iter: 2: Score: 1.509445152027996\n",
      "Iter: 3: Score: 1.5125426966217355\n",
      "Iter: 4: Score: 1.5052631247594594\n",
      "Iter: 5: Score: 1.5280852408742198\n",
      "Iter: 6: Score: 1.5116195100157948\n",
      "Iter: 7: Score: 1.5205597058411122\n",
      "Iter: 8: Score: 1.513929589493652\n",
      "Iter: 9: Score: 1.509629519599801\n",
      "Iter: 10: Score: 1.5017731685576428\n",
      "Iter: 11: Score: 1.5021089376164065\n",
      "Iter: 12: Score: 1.513746253803705\n",
      "Iter: 13: Score: 1.5187191880501574\n",
      "Iter: 14: Score: 1.5099891428561958\n",
      "Iter: 15: Score: 1.4989443036142873\n",
      "Iter: 16: Score: 1.5154909575542221\n",
      "Iter: 17: Score: 1.5024461407387941\n",
      "Iter: 18: Score: 1.5029785661024384\n",
      "Iter: 19: Score: 1.5027201713830636\n",
      "Iter: 20: Score: 1.4997954667688267\n",
      "Iter: 21: Score: 1.505174850910514\n",
      "Iter: 22: Score: 1.5055307641983577\n",
      "Iter: 23: Score: 1.5225365415476044\n",
      "Iter: 24: Score: 1.500117413030041\n",
      "Iter: 25: Score: 1.5145521535055875\n",
      "Iter: 26: Score: 1.5017459720055275\n",
      "Iter: 27: Score: 1.5033256330990596\n",
      "Iter: 28: Score: 1.5100014732976137\n",
      "Iter: 29: Score: 1.5096058105961794\n",
      "Iter: 30: Score: 1.5027609206824413\n",
      "Iter: 31: Score: 1.4996888524142842\n",
      "Iter: 32: Score: 1.5042824913805781\n",
      "Iter: 33: Score: 1.5030933008133807\n",
      "Iter: 34: Score: 1.5026702911666865\n",
      "Iter: 35: Score: 1.510259030779881\n",
      "Iter: 36: Score: 1.5095688996986856\n",
      "Iter: 37: Score: 1.4982561370571246\n",
      "Iter: 38: Score: 1.5108570001291963\n",
      "Iter: 39: Score: 1.4987774759387305\n",
      "Iter: 40: Score: 1.5104545311139597\n",
      "Iter: 41: Score: 1.5051058425187112\n",
      "Iter: 42: Score: 1.5023879893743448\n",
      "Iter: 43: Score: 1.5037211207451473\n",
      "Iter: 44: Score: 1.512069852263926\n",
      "Iter: 45: Score: 1.5090011917419675\n",
      "Iter: 46: Score: 1.5034676331047603\n",
      "Iter: 47: Score: 1.5032862887559382\n",
      "Iter: 48: Score: 1.512323578910121\n",
      "Iter: 49: Score: 1.5009304655909241\n",
      "      scores                                               grid\n",
      "37  1.498256  {'rf__n_estimators': 1100, 'rf__min_weight_fra...\n",
      "Best Model: {'rf__n_estimators': 1100, 'rf__min_weight_fraction_leaf': 0.025, 'rf__max_features': 1, 'rf__max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:00, 120.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45396, 13) (5040, 13)\n",
      "Iter: 0: Score: 1.4386943525847549\n",
      "Iter: 1: Score: 1.4373655654133866\n",
      "Iter: 2: Score: 1.438723856950244\n",
      "Iter: 3: Score: 1.441356256186943\n",
      "Iter: 4: Score: 1.442222511318109\n",
      "Iter: 5: Score: 1.4375445597499412\n",
      "Iter: 6: Score: 1.4373585652446694\n",
      "Iter: 7: Score: 1.4410661382747838\n",
      "Iter: 8: Score: 1.4401827244881014\n",
      "Iter: 9: Score: 1.4398777895562456\n",
      "Iter: 10: Score: 1.4407859539864791\n",
      "Iter: 11: Score: 1.4382021063527664\n",
      "Iter: 12: Score: 1.4441246524716225\n",
      "Iter: 13: Score: 1.4374637528389143\n",
      "Iter: 14: Score: 1.4381816486981343\n",
      "Iter: 15: Score: 1.439980963075644\n",
      "Iter: 16: Score: 1.4395251560051097\n",
      "Iter: 17: Score: 1.4375572105620604\n",
      "Iter: 18: Score: 1.4408446614700945\n",
      "Iter: 19: Score: 1.4397374604646804\n",
      "Iter: 20: Score: 1.437872393080501\n",
      "Iter: 21: Score: 1.4396112200399476\n",
      "Iter: 22: Score: 1.4397579105107312\n",
      "Iter: 23: Score: 1.4397704951168078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:58, 238.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m---> 50\u001b[0m     out \u001b[38;5;241m=\u001b[39m train_single_model(model[\u001b[38;5;241m0\u001b[39m], model[\u001b[38;5;241m1\u001b[39m], model[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     51\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# concat the predictions by columns\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m, in \u001b[0;36mtrain_single_model\u001b[1;34m(model, sampler, model_name)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train2, y_train2\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(y_train2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], ))\n\u001b[0;32m     22\u001b[0m _pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     23\u001b[0m _score \u001b[38;5;241m=\u001b[39m mean_squared_error(y_val, _pred)\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\jaman\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_single_model(model, sampler, model_name):\n",
    "    predictions = []\n",
    "    scores = []\n",
    "    for train, test in tqdm(get_cv_splits(X, split_length=252*5)):\n",
    "        # break out X and y train, test\n",
    "        X_train, y_train = train[features], train[target] \n",
    "        X_test, y_test = test[features], test[target]\n",
    "\n",
    "        # hyper-param loop\n",
    "        X_train2, X_val, y_train2, y_val = train_val_split(X_train, y_train)\n",
    "        print(X_train2.shape, X_val.shape)\n",
    "\n",
    "        # inner loop for parameter tuning\n",
    "        gscv_scores = {'scores': [], 'grid':[]}\n",
    "        for k, p in enumerate(sampler):\n",
    "            model.set_params(**p)\n",
    "            try:\n",
    "                model.n_jobs=-1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            model.fit(X_train2, y_train2.values.reshape(y_train2.shape[0], ))\n",
    "            _pred = model.predict(X_val)\n",
    "            _score = mean_squared_error(y_val, _pred)\n",
    "            gscv_scores['scores'].append(_score)\n",
    "            gscv_scores['grid'].append(p)\n",
    "            print(f'Iter: {k}: Score: {_score}')\n",
    "\n",
    "        # now fit the best model\n",
    "        best_model = pd.DataFrame(gscv_scores).sort_values(by='scores').head(1)['grid'].values[0]\n",
    "        print(pd.DataFrame(gscv_scores).sort_values(by='scores').head(1))\n",
    "        print(f'Best Model: {best_model}')\n",
    "        best_model = model.set_params(**best_model)\n",
    "        best_model.n_jobs=-1\n",
    "        best_model.fit(X_train, y_train.values.reshape(y_train.shape[0], ))\n",
    "        preds = best_model.predict(X_test)\n",
    "\n",
    "        # append the predictions\n",
    "        predictions.append(pd.Series(index=y_test.index, data=preds))\n",
    "       \n",
    "        # score\n",
    "        scores.append(mean_squared_error(y_test, preds))\n",
    "\n",
    "    # predictions\n",
    "    predictions = pd.concat(predictions).to_frame(model_name)\n",
    "    return predictions\n",
    "\n",
    "# train all models selected\n",
    "predictions = []\n",
    "for model in models:\n",
    "    out = train_single_model(model[0], model[1], model[2])\n",
    "    predictions.append(out)\n",
    "\n",
    "# concat the predictions by columns\n",
    "predictions = pd.concat(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check distribution of the targets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'distribution of predictions'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can see predictions go negative at about the 25% percentile, market mainly goes up\n",
    "predictions.plot(kind='hist', bins=1000, title=\"distribution of predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join in predictions with the original dataset which has the cluster returns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Annual_Return Annual_Volatility        DD       MDD    Sharpe  \\\n",
      "preds_MLP_Q_0.0       0.09156          0.212027  0.144234 -0.568615  0.518376   \n",
      "preds_MLP_Q_1.0      0.099061          0.209106  0.147033 -0.526411  0.568821   \n",
      "preds_MLP_Q_2.0      0.069759           0.20818  0.148532 -0.649269  0.449408   \n",
      "preds_MLP_Q_3.0      0.090617          0.212833  0.150864 -0.489226  0.558628   \n",
      "\n",
      "                  Sortino    Calmar ppct_postive_rets  \n",
      "preds_MLP_Q_0.0   0.76202  0.161023           0.54573  \n",
      "preds_MLP_Q_1.0   0.80896  0.188183          0.527525  \n",
      "preds_MLP_Q_2.0  0.629883  0.107443          0.506719  \n",
      "preds_MLP_Q_3.0  0.788093  0.185225               0.5  \n",
      "#################################\n",
      "                 Annual_Return Annual_Volatility        DD       MDD  \\\n",
      "preds_eNet_Q_0.0       0.04934          0.210974  0.149305 -0.688197   \n",
      "preds_eNet_Q_1.0      0.084987          0.211747  0.152664 -0.590507   \n",
      "preds_eNet_Q_2.0       0.07505           0.21156  0.146758 -0.630173   \n",
      "preds_eNet_Q_3.0      0.102337          0.222929  0.149918 -0.546357   \n",
      "\n",
      "                    Sharpe   Sortino    Calmar ppct_postive_rets  \n",
      "preds_eNet_Q_0.0  0.333274   0.47093  0.071695          0.544397  \n",
      "preds_eNet_Q_1.0  0.491621  0.681884  0.143923          0.540803  \n",
      "preds_eNet_Q_2.0  0.447336   0.64486  0.119094          0.540592  \n",
      "preds_eNet_Q_3.0   0.54755  0.814213  0.187308          0.542072  \n",
      "#################################\n",
      "                    Annual_Return Annual_Volatility        DD       MDD  \\\n",
      "preds_eNetPCA_Q_0.0      0.063349           0.21292  0.148409    -0.654   \n",
      "preds_eNetPCA_Q_1.0      0.087235          0.210684  0.151212 -0.612463   \n",
      "preds_eNetPCA_Q_2.0      0.072642          0.217106  0.151177 -0.665974   \n",
      "preds_eNetPCA_Q_3.0      0.088173          0.216023  0.147338 -0.531075   \n",
      "\n",
      "                       Sharpe   Sortino    Calmar ppct_postive_rets  \n",
      "preds_eNetPCA_Q_0.0   0.39411  0.565423  0.096864          0.541226  \n",
      "preds_eNetPCA_Q_1.0  0.502824  0.700583  0.142434          0.540803  \n",
      "preds_eNetPCA_Q_2.0  0.431078  0.619071  0.109076          0.540803  \n",
      "preds_eNetPCA_Q_3.0   0.49844  0.730803  0.166028          0.539112  \n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "# Bring in the data\n",
    "data = load_features_data()\n",
    "\n",
    "# join in predictions\n",
    "predictions = predictions.merge(data, how=\"left\", left_index=True, right_index=True)\n",
    "predictions.sort_index(inplace=True)\n",
    "\n",
    "# get the prediction columns\n",
    "pred_cols = [f for f in predictions.columns if f.startswith('preds_')]\n",
    "\n",
    "def getRetsForStrat(predictions, pred_cols):\n",
    "    ret_list = []\n",
    "    for pred_col in pred_cols:\n",
    "        predictions[f'{pred_col}_signalQ'] = predictions.groupby(by='date')[pred_col].apply(lambda x: pd.qcut(x, 4, labels=False, duplicates='drop')).droplevel(0)\n",
    "        predictions[f'{pred_col}_signalQ'] = predictions.groupby(by='cluster')[f'{pred_col}_signalQ'].shift(1)\n",
    "        rets = predictions.groupby(by=['date', f'{pred_col}_signalQ'])['1d_ret'].mean().unstack()\n",
    "        rets.rename(columns={col: f'{pred_col}_Q_{col}' for col in rets.columns}, inplace=True)\n",
    "        ret_list.append(rets)\n",
    "    return ret_list\n",
    "\n",
    "ret_breakouts = []\n",
    "# get all the returns\n",
    "all_rets = getRetsForStrat(predictions, pred_cols)\n",
    "for one_ret in all_rets:\n",
    "    print(get_returns_breakout(one_ret))\n",
    "    ret_breakouts.append(get_returns_breakout(one_ret))\n",
    "    print('#################################')\n",
    "\n",
    "# stack the returns\n",
    "stacked_strat_rets = pd.concat([r.stack().to_frame('ret') for r in all_rets]) # this can hopefully be the data used for streamlit\n",
    "stacked_strat_rets_cumprod = (1+stacked_strat_rets.unstack()).cumprod()\n",
    "\n",
    "# save to pickle\n",
    "stacked_strat_rets_cumprod.columns = stacked_strat_rets_cumprod.columns.droplevel(0)\n",
    "stacked_strat_rets_cumprod.to_pickle(\"cum_cluster_returns.pkl\")\n",
    "pd.concat(ret_breakouts).to_pickle(\"metrics_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
